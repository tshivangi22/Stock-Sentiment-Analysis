{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "WJ0Rd33q1cAL",
    "outputId": "249dc91b-11f8-4b5f-a6c6-088c7fceffd8"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"enhanced_sentiment_stock_data.csv\")\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XiCxTZSmom-7",
    "outputId": "3992a7e8-535b-41ed-bb5a-3780b50335ff"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"enhanced_sentiment_stock_data.csv\")\n",
    "\n",
    "# Define required feature columns\n",
    "required_columns = [\n",
    "    'CloseMA_3', 'CloseMA_5', 'CloseMA_10',\n",
    "    'RSI', 'MACD', 'MACD_Signal',\n",
    "    'BB_Upper', 'BB_Lower',\n",
    "    'Volatility', 'Return', 'Volume_MA'\n",
    "]\n",
    "\n",
    "# Drop rows with missing values in either features or target\n",
    "df_clean = df.dropna(subset=required_columns + ['Sentiment_Enhanced'])\n",
    "\n",
    "# Define feature matrix X and target vector y\n",
    "X = df_clean[required_columns]\n",
    "y = df_clean['Sentiment_Enhanced']\n",
    "\n",
    "# Check class balance\n",
    "print(X.shape)\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "JNk_E_qcoxCG",
    "outputId": "7ade7877-94fc-45ee-a18a-309151750c4e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=['Bullish','Bearish','Neutral'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=['Bullish','Bearish','Neutral'], yticklabels=['Bullish','Bearish','Neutral'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogx1zLx2qrsq",
    "outputId": "9c8ca376-d294-4a5f-b59d-f361b045c8a2"
   },
   "outputs": [],
   "source": [
    "# Predict on full cleaned dataset\n",
    "df_clean['ML_Predicted'] = model.predict(X)\n",
    "\n",
    "# Map to Action\n",
    "action_map = {'Bullish': 'Buy', 'Bearish': 'Sell', 'Neutral': 'Hold'}\n",
    "df_clean['Action'] = df_clean['ML_Predicted'].map(action_map)\n",
    "\n",
    "# Save to CSV\n",
    "df_clean.to_csv('ml_predictions.csv', index=False)\n",
    "print(\"Saved file: ml_predictions.csv\")\n",
    "\n",
    "# Check sample\n",
    "print(df_clean[['Date','Close','Sentiment_Enhanced','ML_Predicted','Action']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "GFUtTtLArB8C",
    "outputId": "9dbde073-52e4-4b9b-d560-d5dc883902e3"
   },
   "outputs": [],
   "source": [
    "# Strategy 1 – Basic ML Backtest (No Risk Mgmt)\n",
    "initial_capital = 100000\n",
    "position = 0  # 0 means no position, 1 means long\n",
    "entry_price = 0\n",
    "cash = initial_capital\n",
    "portfolio_value = []\n",
    "trade_log = []\n",
    "\n",
    "for i, row in df_clean.iterrows():\n",
    "    action = row['Action']\n",
    "    price = row['Close']\n",
    "\n",
    "    if action == 'Buy' and position == 0:\n",
    "        position = 1\n",
    "        entry_price = price\n",
    "        trade_log.append({'Date': row['Date'], 'Action': 'Buy', 'Price': price})\n",
    "\n",
    "    elif action == 'Sell' and position == 1:\n",
    "        position = 0\n",
    "        pnl = (price - entry_price)\n",
    "        cash += pnl\n",
    "        trade_log.append({'Date': row['Date'], 'Action': 'Sell', 'Price': price, 'PnL': pnl})\n",
    "\n",
    "    # Track portfolio value\n",
    "    current_value = cash + (price - entry_price if position == 1 else 0)\n",
    "    portfolio_value.append(current_value)\n",
    "\n",
    "# Add portfolio value to dataframe\n",
    "df_clean['Portfolio_Value'] = portfolio_value\n",
    "\n",
    "# Convert trade log to DataFrame\n",
    "trade_df = pd.DataFrame(trade_log)\n",
    "\n",
    "# Final results\n",
    "final_value = portfolio_value[-1]\n",
    "total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "\n",
    "print(f\"Final Portfolio Value: {final_value:.2f}\")\n",
    "print(f\"Total Return: {total_return:.2f}%\")\n",
    "print(f\"Number of Trades: {len(trade_df)//2}\")\n",
    "\n",
    "# Save trade log\n",
    "trade_df.to_csv('ml_trade_log.csv', index=False)\n",
    "\n",
    "# Plot portfolio value\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_clean['Date'], df_clean['Portfolio_Value'], label='ML Strategy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Portfolio Value Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "hsEWoaGrrmzF",
    "outputId": "91532f70-4858-4353-8b10-d14f22ff8c34"
   },
   "outputs": [],
   "source": [
    "# Strategy 2 – Improved ML Backtest (MA Filter)\n",
    "initial_capital = 100000\n",
    "cash = initial_capital\n",
    "position = 0  # 0 = no position, 1 = long\n",
    "entry_price = 0\n",
    "portfolio_value = []\n",
    "trade_log = []\n",
    "\n",
    "for i, row in df_clean.iterrows():\n",
    "    signal = row['ML_Predicted']\n",
    "    price = row['Close']\n",
    "    ma10 = row['CloseMA_10']\n",
    "\n",
    "    # Stop-loss / Take-profit check\n",
    "    if position == 1:\n",
    "        if price <= entry_price * 0.98 or price >= entry_price * 1.04:\n",
    "            pnl = price - entry_price\n",
    "            cash += pnl\n",
    "            trade_log.append({'Date': row['Date'], 'Action': 'Exit (Stop/TP)', 'Price': price, 'PnL': pnl})\n",
    "            position = 0\n",
    "\n",
    "    # Entry condition\n",
    "    if signal == 'Bullish' and position == 0 and price > ma10:\n",
    "        position = 1\n",
    "        entry_price = price\n",
    "        trade_log.append({'Date': row['Date'], 'Action': 'Buy', 'Price': price})\n",
    "\n",
    "    # Exit condition\n",
    "    elif signal == 'Bearish' and position == 1 and price < ma10:\n",
    "        position = 0\n",
    "        pnl = price - entry_price\n",
    "        cash += pnl\n",
    "        trade_log.append({'Date': row['Date'], 'Action': 'Sell', 'Price': price, 'PnL': pnl})\n",
    "\n",
    "    # Track portfolio value\n",
    "    current_value = cash + (price - entry_price if position == 1 else 0)\n",
    "    portfolio_value.append(current_value)\n",
    "\n",
    "df_clean['Portfolio_Value_Improved'] = portfolio_value\n",
    "trade_df = pd.DataFrame(trade_log)\n",
    "\n",
    "final_value = portfolio_value[-1]\n",
    "total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "\n",
    "print(f\"Final Portfolio Value: {final_value:.2f}\")\n",
    "print(f\"Total Return: {total_return:.2f}%\")\n",
    "print(f\"Number of Trades: {len(trade_df)//2}\")\n",
    "\n",
    "# Save trade log\n",
    "trade_df.to_csv('ml_trade_log_improved.csv', index=False)\n",
    "\n",
    "# Plot portfolio value\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_clean['Date'], df_clean['Portfolio_Value_Improved'], label='Improved ML Strategy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Improved ML Strategy Portfolio Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_4uw1cQtN4Z",
    "outputId": "45ee93c2-f45e-4edd-c500-0e49a8a81a0b"
   },
   "outputs": [],
   "source": [
    "# Backtesting ML Strategy with Probability-Filtered Signals and Risk Management\n",
    "# Get prediction probabilities for full dataset\n",
    "proba = model.predict_proba(X)\n",
    "classes = model.classes_  # ['Bearish','Bullish','Neutral']\n",
    "\n",
    "# Add predicted probabilities\n",
    "df_clean['Prob_Bearish'] = proba[:, list(classes).index('Bearish')]\n",
    "df_clean['Prob_Bullish'] = proba[:, list(classes).index('Bullish')]\n",
    "df_clean['Prob_Neutral'] = proba[:, list(classes).index('Neutral')]\n",
    "\n",
    "# Improved backtest with probability filter\n",
    "initial_capital = 100000\n",
    "cash = initial_capital\n",
    "position = 0\n",
    "entry_price = 0\n",
    "portfolio_value = []\n",
    "trade_log = []\n",
    "threshold = 0.65  # confidence threshold\n",
    "\n",
    "for i, row in df_clean.iterrows():\n",
    "    price = row['Close']\n",
    "    ma10 = row['CloseMA_10']\n",
    "    prob_bullish = row['Prob_Bullish']\n",
    "    prob_bearish = row['Prob_Bearish']\n",
    "\n",
    "    # Stop-loss / Take-profit check\n",
    "    if position == 1:\n",
    "        if price <= entry_price * 0.98 or price >= entry_price * 1.06:\n",
    "            pnl = price - entry_price\n",
    "            cash += pnl\n",
    "            trade_log.append({'Date': row['Date'], 'Action': 'Exit (Stop/TP)', 'Price': price, 'PnL': pnl})\n",
    "            position = 0\n",
    "\n",
    "    # Entry: Bullish with high confidence and trend\n",
    "    if prob_bullish > threshold and position == 0 and price > ma10:\n",
    "        position = 1\n",
    "        entry_price = price\n",
    "        trade_log.append({'Date': row['Date'], 'Action': 'Buy', 'Price': price})\n",
    "\n",
    "    # Exit: Bearish with high confidence and trend\n",
    "    elif prob_bearish > threshold and position == 1 and price < ma10:\n",
    "        position = 0\n",
    "        pnl = price - entry_price\n",
    "        cash += pnl\n",
    "        trade_log.append({'Date': row['Date'], 'Action': 'Sell', 'Price': price, 'PnL': pnl})\n",
    "\n",
    "    current_value = cash + (price - entry_price if position == 1 else 0)\n",
    "    portfolio_value.append(current_value)\n",
    "\n",
    "df_clean['Portfolio_Value_RF_Prob'] = portfolio_value\n",
    "trade_df_rf = pd.DataFrame(trade_log)\n",
    "\n",
    "final_value_rf = portfolio_value[-1]\n",
    "total_return_rf = ((final_value_rf - initial_capital) / initial_capital) * 100\n",
    "\n",
    "print(f\"Final Portfolio Value (RF Improved): {final_value_rf:.2f}\")\n",
    "print(f\"Total Return: {total_return_rf:.2f}%\")\n",
    "print(f\"Number of Trades: {len(trade_df_rf)//2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vChhLkosRHLV",
    "outputId": "c162b31c-b060-4db6-bf52-8dcfb3decc6f"
   },
   "outputs": [],
   "source": [
    "df_clean['Future_Close'] = df_clean['Close'].shift(-1)\n",
    "df_clean['Target'] = (df_clean['Future_Close'] > df_clean['Close']).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyTT99S4SDdQ",
    "outputId": "88749202-f185-45d9-aae1-3460c046c84b"
   },
   "outputs": [],
   "source": [
    "df_clean['Date'] = pd.to_datetime(df_clean['Date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvGL7joeRx_W",
    "outputId": "c0b9a2b2-3e60-4edd-efe5-6460c2ae77ca"
   },
   "outputs": [],
   "source": [
    "# Enhanced Feature Set for Model Training\n",
    "# Lagged Returns\n",
    "df_clean['Return_1d'] = df_clean['Return']\n",
    "df_clean['Return_3d'] = df_clean['Close'].pct_change(3)\n",
    "df_clean['Return_5d'] = df_clean['Close'].pct_change(5)\n",
    "\n",
    "# Rolling Volatility\n",
    "df_clean['Volatility_3d'] = df_clean['Return'].rolling(3).std()\n",
    "df_clean['Volatility_10d'] = df_clean['Return'].rolling(10).std()\n",
    "\n",
    "# Momentum / Trend\n",
    "df_clean['MA_diff'] = df_clean['CloseMA_5'] - df_clean['CloseMA_10']\n",
    "df_clean['RSI_Change'] = df_clean['RSI'].diff()\n",
    "\n",
    "# Volume Breakout\n",
    "df_clean['Volume_Ratio'] = df_clean['Volume'] / df_clean['Volume_MA']\n",
    "\n",
    "# Candlestick Body Size\n",
    "df_clean['Candle_Body'] = df_clean['Close'] - df_clean['Open']\n",
    "\n",
    "# Time Features\n",
    "df_clean['DayOfWeek'] = df_clean['Date'].dt.dayofweek\n",
    "df_clean['Month'] = df_clean['Date'].dt.month\n",
    "\n",
    "# Enhanced Sentiment Numeric\n",
    "df_clean['Sentiment_Num'] = df_clean['Sentiment_Enhanced'].map({'Bullish': 1, 'Bearish': -1, 'Neutral': 0})\n",
    "\n",
    "# Drop rows with NaN from rolling/lags\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "# Define new feature set\n",
    "feature_cols = [\n",
    "    'CloseMA_3','CloseMA_5','CloseMA_10','RSI','MACD','MACD_Signal',\n",
    "    'BB_Upper','BB_Lower','Volatility','Volume_MA',\n",
    "    'Return_1d','Return_3d','Return_5d',\n",
    "    'Volatility_3d','Volatility_10d',\n",
    "    'MA_diff','RSI_Change','Volume_Ratio','Candle_Body',\n",
    "    'DayOfWeek','Month','Sentiment_Num'\n",
    "]\n",
    "\n",
    "X_new = df_clean[feature_cols]\n",
    "y_new = df_clean['Target']\n",
    "\n",
    "print(X_new.shape, y_new.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "fRFFnQQ4SGEx",
    "outputId": "8e978b20-0bb6-4524-f012-6be270b2f13a"
   },
   "outputs": [],
   "source": [
    "# Training and Evaluating XGBoost Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define X and y\n",
    "X_new = df_clean[feature_cols]\n",
    "y_new = df_clean['Target']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, stratify=y_new, random_state=42)\n",
    "\n",
    "# Train XGBoost with tuned parameters\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks([0,1], ['Down','Up'])\n",
    "plt.yticks([0,1], ['Down','Up'])\n",
    "plt.colorbar()\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i,j], ha='center', va='center', color='white' if cm[i,j]>cm.max()/2 else 'black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwJ59q09VRp8",
    "outputId": "384d8a15-3e16-4649-f6ec-83a0977147da"
   },
   "outputs": [],
   "source": [
    "# Creating 3-Day Future Price Movement Target\n",
    "# Target Engineering: 3-Day Price Increase Classification\n",
    "# Create new target for 3-day horizon\n",
    "df_clean['Future_Close_3d'] = df_clean['Close'].shift(-3)\n",
    "df_clean['Target_3d'] = ((df_clean['Future_Close_3d'] - df_clean['Close']) / df_clean['Close'] > 0.005).astype(int)\n",
    "\n",
    "# Drop last 3 rows because they have NaN in Future_Close_3d\n",
    "df_clean = df_clean.dropna(subset=['Future_Close_3d'])\n",
    "\n",
    "# Check class balance\n",
    "print(df_clean['Target_3d'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "gjLkoiiNWEDL",
    "outputId": "dfd1c6c4-0947-442f-be6b-46b5f190595e"
   },
   "outputs": [],
   "source": [
    "# 3-Day Horizon Price Movement Classification with XGBoost\n",
    "# Modeling Future Price Increases: Training and Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define features and new target\n",
    "X_new = df_clean[feature_cols]\n",
    "y_new = df_clean['Target_3d']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, stratify=y_new, random_state=42)\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks([0,1], ['No Rise','Rise'])\n",
    "plt.yticks([0,1], ['No Rise','Rise'])\n",
    "plt.colorbar()\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i,j], ha='center', va='center', color='white' if cm[i,j]>cm.max()/2 else 'black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSM_sS-UWP-e",
    "outputId": "59508f76-8687-4e3c-c1fb-21def8c23f57"
   },
   "outputs": [],
   "source": [
    "# Trading Simulation Using XGBoost Probability and Enhanced Sentiment\n",
    "# Get predicted probabilities\n",
    "proba = xgb_model.predict_proba(X_new)\n",
    "df_clean['Prob_Rise'] = proba[:, 1]\n",
    "\n",
    "# Initialize variables for backtest\n",
    "initial_capital = 100000\n",
    "cash = initial_capital\n",
    "position = 0\n",
    "portfolio_values = []\n",
    "trade_log = []\n",
    "\n",
    "for i in range(len(df_clean)):\n",
    "    price = df_clean['Close'].iloc[i]\n",
    "    sentiment = df_clean['Sentiment_Enhanced'].iloc[i]\n",
    "    prob_rise = df_clean['Prob_Rise'].iloc[i]\n",
    "\n",
    "    # Buy condition\n",
    "    if position == 0 and prob_rise >= 0.8 and sentiment == 'Bullish':\n",
    "        position = cash / price\n",
    "        cash = 0\n",
    "        trade_log.append(('BUY', df_clean['Date'].iloc[i], price))\n",
    "\n",
    "    # Sell condition\n",
    "    elif position > 0 and prob_rise <= 0.2 and sentiment == 'Bearish':\n",
    "        cash = position * price\n",
    "        position = 0\n",
    "        trade_log.append(('SELL', df_clean['Date'].iloc[i], price))\n",
    "\n",
    "    # Portfolio value\n",
    "    portfolio_value = cash + (position * price if position > 0 else 0)\n",
    "    portfolio_values.append(portfolio_value)\n",
    "\n",
    "df_clean['Portfolio_Value_OptionC'] = portfolio_values\n",
    "\n",
    "# Final results\n",
    "final_value = portfolio_values[-1]\n",
    "total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "\n",
    "print(f\"Final Portfolio Value: {final_value:.2f}\")\n",
    "print(f\"Total Return: {total_return:.2f}%\")\n",
    "print(f\"Number of Trades: {len(trade_log)//2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "NORWC1tsVBmi",
    "outputId": "e247467d-b017-44f2-f461-9ffc683cfed4"
   },
   "outputs": [],
   "source": [
    "# Visualizing Backtest Portfolio Value Over Time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_clean['Date'], df_clean['Portfolio_Value_OptionC'], label='Option C Strategy', linewidth=2)\n",
    "plt.title('Portfolio Value Over Time - Option C Strategy')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_6h_z5FVzsG",
    "outputId": "22c6d998-dd3f-4381-ec81-a439e40651ce"
   },
   "outputs": [],
   "source": [
    "# Creating Trade-by-Trade Analysis Table\n",
    "import pandas as pd\n",
    "\n",
    "trade_details = []\n",
    "current_trade = {}\n",
    "\n",
    "for action, date, price in trade_log:\n",
    "    if action == 'BUY':\n",
    "        current_trade['Buy_Date'] = date\n",
    "        current_trade['Buy_Price'] = price\n",
    "    elif action == 'SELL' and current_trade:\n",
    "        current_trade['Sell_Date'] = date\n",
    "        current_trade['Sell_Price'] = price\n",
    "        current_trade['PnL'] = current_trade['Sell_Price'] - current_trade['Buy_Price']\n",
    "        current_trade['Return_%'] = ((current_trade['Sell_Price'] - current_trade['Buy_Price']) / current_trade['Buy_Price']) * 100\n",
    "        current_trade['Holding_Days'] = (pd.to_datetime(current_trade['Sell_Date']) - pd.to_datetime(current_trade['Buy_Date'])).days\n",
    "        trade_details.append(current_trade)\n",
    "        current_trade = {}\n",
    "\n",
    "trade_df = pd.DataFrame(trade_details)\n",
    "print(trade_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHsAsLj4a7PF",
    "outputId": "ca596960-84ce-4e04-ba3d-ad088cc3686d"
   },
   "outputs": [],
   "source": [
    "# Performance Metrics Calculation and Export to Excel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Trade Log DataFrame\n",
    "trade_details = []\n",
    "current_trade = {}\n",
    "\n",
    "for action, date, price in trade_log:\n",
    "    if action == 'BUY':\n",
    "        current_trade['Buy_Date'] = date\n",
    "        current_trade['Buy_Price'] = price\n",
    "    elif action == 'SELL' and current_trade:\n",
    "        current_trade['Sell_Date'] = date\n",
    "        current_trade['Sell_Price'] = price\n",
    "        current_trade['PnL'] = current_trade['Sell_Price'] - current_trade['Buy_Price']\n",
    "        current_trade['Return_%'] = ((current_trade['Sell_Price'] - current_trade['Buy_Price']) / current_trade['Buy_Price']) * 100\n",
    "        current_trade['Holding_Days'] = (pd.to_datetime(current_trade['Sell_Date']) - pd.to_datetime(current_trade['Buy_Date'])).days\n",
    "        trade_details.append(current_trade)\n",
    "        current_trade = {}\n",
    "\n",
    "trade_df = pd.DataFrame(trade_details)\n",
    "\n",
    "# 2. Portfolio Curve DataFrame\n",
    "portfolio_curve_df = df_clean[['Date', 'Portfolio_Value_OptionC']].copy()\n",
    "\n",
    "# 3. Performance Summary\n",
    "final_value = portfolio_values[-1]\n",
    "total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "cagr = ((final_value / initial_capital) ** (252 / len(df_clean)) - 1) * 100  # Assuming 252 trading days\n",
    "returns = portfolio_curve_df['Portfolio_Value_OptionC'].pct_change().dropna()\n",
    "sharpe_ratio = (returns.mean() / returns.std()) * np.sqrt(252) if returns.std() != 0 else 0\n",
    "rolling_max = portfolio_curve_df['Portfolio_Value_OptionC'].cummax()\n",
    "drawdown = (portfolio_curve_df['Portfolio_Value_OptionC'] - rolling_max) / rolling_max\n",
    "max_drawdown = drawdown.min() * 100\n",
    "\n",
    "summary_data = {\n",
    "    'Metric': ['Final Portfolio Value', 'Total Return (%)', 'CAGR (%)', 'Sharpe Ratio', 'Max Drawdown (%)', 'Number of Trades'],\n",
    "    'Value': [final_value, total_return, cagr, sharpe_ratio, max_drawdown, len(trade_df)]\n",
    "}\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Save all to Excel\n",
    "with pd.ExcelWriter(\"OptionC_Strategy_Report.xlsx\") as writer:\n",
    "    trade_df.to_excel(writer, sheet_name=\"Trade_Log\", index=False)\n",
    "    portfolio_curve_df.to_excel(writer, sheet_name=\"Portfolio_Curve\", index=False)\n",
    "    summary_df.to_excel(writer, sheet_name=\"Performance_Summary\", index=False)\n",
    "\n",
    "print(\"✅ Option C Strategy Report saved as 'OptionC_Strategy_Report.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4Z7ykT9gpAS",
    "outputId": "1ff5fa35-e80c-4db2-ce56-cbeea3751f89"
   },
   "outputs": [],
   "source": [
    "# Consolidated Report: Original, Enhanced, and ML-Predicted Strategies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "initial_capital = 100000\n",
    "\n",
    "# Load Option C (ML Strategy) portfolio values\n",
    "xls = pd.ExcelFile(\"OptionC_Strategy_Report.xlsx\")\n",
    "df_optionc_portfolio = xls.parse(\"Portfolio_Curve\")\n",
    "df_optionc_portfolio = df_optionc_portfolio.dropna(subset=[\"Portfolio_Value_OptionC\"])\n",
    "portfolio_optionc = df_optionc_portfolio[[\"Date\", \"Portfolio_Value_OptionC\"]].copy()\n",
    "portfolio_optionc.rename(columns={\"Portfolio_Value_OptionC\": \"Portfolio_Value\"}, inplace=True)\n",
    "\n",
    "# Load trade logs for Original and Enhanced strategies\n",
    "df_original = pd.read_csv(\"trades_sentiment.csv\")  # must contain: Date, Action, Price, Shares\n",
    "df_enhanced = pd.read_csv(\"trades_sentiment_enhanced.csv\")  # must contain: Date, Action, Price, Shares\n",
    "\n",
    "def compute_portfolio_curve_from_actions(trade_log, initial_capital):\n",
    "    portfolio_value = [initial_capital]\n",
    "    dates = []\n",
    "    current_trade = {}\n",
    "\n",
    "    for _, row in trade_log.iterrows():\n",
    "        if row['Action'] == 'BUY':\n",
    "            current_trade['Buy_Price'] = row['Price']\n",
    "            current_trade['Shares'] = row['Shares']\n",
    "        elif row['Action'] == 'SELL' and current_trade:\n",
    "            sell_price = row['Price']\n",
    "            pnl = (sell_price - current_trade['Buy_Price']) * current_trade['Shares']\n",
    "            portfolio_value.append(portfolio_value[-1] + pnl)\n",
    "            dates.append(row['Date'])\n",
    "            current_trade = {}\n",
    "\n",
    "    return pd.DataFrame({'Date': dates, 'Portfolio_Value': portfolio_value[1:]})\n",
    "\n",
    "# Compute portfolio curves\n",
    "portfolio_original = compute_portfolio_curve_from_actions(df_original, initial_capital)\n",
    "portfolio_enhanced = compute_portfolio_curve_from_actions(df_enhanced, initial_capital)\n",
    "\n",
    "# Performance calculation\n",
    "def calculate_performance(portfolio_df):\n",
    "    final_value = portfolio_df['Portfolio_Value'].iloc[-1]\n",
    "    total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "    cagr = ((final_value / initial_capital) ** (252 / len(portfolio_df)) - 1) * 100\n",
    "    returns = portfolio_df['Portfolio_Value'].pct_change().dropna()\n",
    "    sharpe = (returns.mean() / returns.std()) * np.sqrt(252) if returns.std() != 0 else 0\n",
    "    max_dd = (portfolio_df['Portfolio_Value'] / portfolio_df['Portfolio_Value'].cummax() - 1).min() * 100\n",
    "    return [final_value, total_return, cagr, sharpe, max_dd]\n",
    "\n",
    "# Prepare comparison table\n",
    "summary = []\n",
    "summary.append(['Original', *calculate_performance(portfolio_original), len(df_original) // 2])\n",
    "summary.append(['Enhanced', *calculate_performance(portfolio_enhanced), len(df_enhanced) // 2])\n",
    "summary.append(['ML-Predicted (Option C)', *calculate_performance(portfolio_optionc), len(xls.parse(\"Trade_Log\"))])\n",
    "\n",
    "comparison_df = pd.DataFrame(summary, columns=[\n",
    "    'Strategy', 'Final Value', 'Total Return (%)', 'CAGR (%)',\n",
    "    'Sharpe Ratio', 'Max Drawdown (%)', 'Number of Trades'\n",
    "])\n",
    "\n",
    "# Save to Excel\n",
    "with pd.ExcelWriter(\"All_Strategies_Report.xlsx\") as writer:\n",
    "    comparison_df.to_excel(writer, sheet_name=\"Comparison\", index=False)\n",
    "    df_original.to_excel(writer, sheet_name=\"Original_Trades\", index=False)\n",
    "    df_enhanced.to_excel(writer, sheet_name=\"Enhanced_Trades\", index=False)\n",
    "    xls.parse(\"Trade_Log\").to_excel(writer, sheet_name=\"OptionC_Trades\", index=False)\n",
    "    portfolio_original.to_excel(writer, sheet_name=\"Original_Curve\", index=False)\n",
    "    portfolio_enhanced.to_excel(writer, sheet_name=\"Enhanced_Curve\", index=False)\n",
    "    portfolio_optionc.to_excel(writer, sheet_name=\"OptionC_Curve\", index=False)\n",
    "\n",
    "print(\"✅ All strategies report saved to 'All_Strategies_Report.xlsx'\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "1Higgp8dhjh6",
    "outputId": "8d0bae25-8e49-4db7-db42-0488af73ffb7"
   },
   "outputs": [],
   "source": [
    "# Portfolio Value Comparison: Original vs Enhanced vs ML Strategies\n",
    "# Ensure all Date columns are datetime\n",
    "portfolio_original['Date'] = pd.to_datetime(portfolio_original['Date'])\n",
    "portfolio_enhanced['Date'] = pd.to_datetime(portfolio_enhanced['Date'])\n",
    "portfolio_optionc['Date'] = pd.to_datetime(portfolio_optionc['Date'], errors='coerce')\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(portfolio_original['Date'], portfolio_original['Portfolio_Value'], label='Original Sentiment', color='red')\n",
    "plt.plot(portfolio_enhanced['Date'], portfolio_enhanced['Portfolio_Value'], label='Enhanced Sentiment', color='blue')\n",
    "plt.plot(portfolio_optionc['Date'], portfolio_optionc['Portfolio_Value'], label='Option C (ML)', color='green')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.title('Portfolio Value Comparison of All Strategies')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ds8oGPVTk4Bo",
    "outputId": "3f141ffb-f02c-4b81-a75a-1a5a6bf34c6d"
   },
   "outputs": [],
   "source": [
    "# Accurate Strategy Comparison Based on Reconstructed Trades\n",
    "# Calculating CAGR, Sharpe, and Drawdown from Trade Logs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to reconstruct trades from logs\n",
    "def reconstruct_trades(df):\n",
    "    trades = []\n",
    "    current_trade = {}\n",
    "    for _, row in df.iterrows():\n",
    "        if row['Action'] == 'BUY':\n",
    "            current_trade['Buy_Date'] = row['Date']\n",
    "            current_trade['Buy_Price'] = row['Price']\n",
    "        elif row['Action'] == 'SELL' and current_trade:\n",
    "            current_trade['Sell_Date'] = row['Date']\n",
    "            current_trade['Sell_Price'] = row['Price']\n",
    "            trades.append(current_trade)\n",
    "            current_trade = {}\n",
    "    return pd.DataFrame(trades)\n",
    "\n",
    "# Function to compute portfolio stats from trades\n",
    "def calculate_portfolio_stats(trade_df, strategy_name, initial_capital=100000):\n",
    "    if len(trade_df) == 0:\n",
    "        return {\n",
    "            'Strategy': strategy_name,\n",
    "            'Final Value': initial_capital,\n",
    "            'Total Return (%)': 0,\n",
    "            'CAGR (%)': 0,\n",
    "            'Sharpe Ratio': 0,\n",
    "            'Max Drawdown (%)': 0,\n",
    "            'Number of Trades': 0\n",
    "        }\n",
    "\n",
    "    capital = initial_capital\n",
    "    shares = 0\n",
    "    portfolio_values = [capital]\n",
    "    dates = []\n",
    "\n",
    "    for _, row in trade_df.iterrows():\n",
    "        date = pd.to_datetime(row['Buy_Date'] if 'Buy_Date' in row else row['Sell_Date'])\n",
    "        if 'Buy_Price' in row and pd.notna(row['Buy_Price']):\n",
    "            # Buy trade\n",
    "            shares = capital / row['Buy_Price']\n",
    "            capital = 0\n",
    "        if 'Sell_Price' in row and pd.notna(row['Sell_Price']):\n",
    "            # Sell trade\n",
    "            capital = shares * row['Sell_Price']\n",
    "            shares = 0\n",
    "        portfolio_values.append(capital)\n",
    "        dates.append(date)\n",
    "\n",
    "    final_value = capital\n",
    "    total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "\n",
    "    # Duration for CAGR\n",
    "    if len(dates) > 1:\n",
    "        days = (max(dates) - min(dates)).days\n",
    "        years = days / 365 if days > 0 else 1\n",
    "    else:\n",
    "        years = 1\n",
    "    CAGR = ((final_value / initial_capital) ** (1 / years) - 1) * 100\n",
    "\n",
    "    # Sharpe Ratio and Max Drawdown\n",
    "    portfolio_series = pd.Series(portfolio_values)\n",
    "    daily_returns = portfolio_series.pct_change().dropna()\n",
    "    sharpe_ratio = (daily_returns.mean() / daily_returns.std()) * np.sqrt(252) if daily_returns.std() > 0 else 0\n",
    "    peak = portfolio_series.cummax()\n",
    "    drawdown = (portfolio_series - peak) / peak\n",
    "    max_drawdown = drawdown.min() * 100\n",
    "\n",
    "    return {\n",
    "        'Strategy': strategy_name,\n",
    "        'Final Value': round(final_value, 2),\n",
    "        'Total Return (%)': round(total_return, 2),\n",
    "        'CAGR (%)': round(CAGR, 2),\n",
    "        'Sharpe Ratio': round(sharpe_ratio, 4),\n",
    "        'Max Drawdown (%)': round(max_drawdown, 2),\n",
    "        'Number of Trades': len(trade_df)\n",
    "    }\n",
    "\n",
    "# Load trade logs\n",
    "original_trades = pd.read_csv(\"trades_sentiment.csv\")\n",
    "enhanced_trades = pd.read_csv(\"trades_sentiment_enhanced.csv\")\n",
    "\n",
    "# Reconstruct summaries\n",
    "original_trades_summary = reconstruct_trades(original_trades)\n",
    "enhanced_trades_summary = reconstruct_trades(enhanced_trades)\n",
    "\n",
    "# Calculate stats for all\n",
    "stats_original = calculate_portfolio_stats(original_trades_summary, 'Original Sentiment')\n",
    "stats_enhanced = calculate_portfolio_stats(enhanced_trades_summary, 'Enhanced Sentiment')\n",
    "stats_optionc = calculate_portfolio_stats(trade_df, 'Option C (ML)')  # trade_df = ML trades\n",
    "\n",
    "# Combine results\n",
    "trade_stats_df = pd.DataFrame([stats_original, stats_enhanced, stats_optionc])\n",
    "print(trade_stats_df)\n",
    "\n",
    "# Save to Excel\n",
    "trade_stats_df.to_excel('Trade_Statistics_Comparison.xlsx', index=False)\n",
    "print(\"✅ Corrected strategy comparison saved as 'Trade_Statistics_Comparison.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "xkA1VTO1l9fa",
    "outputId": "47884cb0-d480-4b04-fd03-4c86e686bb96"
   },
   "outputs": [],
   "source": [
    "# Holding Time Analysis of ML-Based Trades\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot distribution of holding times\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(trade_df['Holding_Days'], bins=15, kde=True, color='green')\n",
    "plt.title('Holding Time Distribution (Option C - ML Strategy)')\n",
    "plt.xlabel('Holding Days')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-EIiwgzmepM"
   },
   "outputs": [],
   "source": [
    "# Add PnL and Holding Days for original and enhanced\n",
    "for df in [original_trades_summary, enhanced_trades_summary]:\n",
    "    df['PnL'] = df['Sell_Price'] - df['Buy_Price']\n",
    "    df['Return_%'] = ((df['Sell_Price'] - df['Buy_Price']) / df['Buy_Price']) * 100\n",
    "    df['Holding_Days'] = (pd.to_datetime(df['Sell_Date']) - pd.to_datetime(df['Buy_Date'])).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "M8SmOf5vmkhw",
    "outputId": "701ab771-c011-4139-fdd8-7f167a081d9a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(original_trades_summary['Holding_Days'], bins=15, kde=False, color='red', label='Original', alpha=0.5)\n",
    "sns.histplot(enhanced_trades_summary['Holding_Days'], bins=15, kde=False, color='blue', label='Enhanced', alpha=0.5)\n",
    "sns.histplot(trade_df['Holding_Days'], bins=15, kde=False, color='green', label='Option C (ML)', alpha=0.5)\n",
    "\n",
    "plt.title('Holding Time Distribution Comparison')\n",
    "plt.xlabel('Holding Days')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "1reuPf99mo5M",
    "outputId": "d84c8be1-27fe-4fd5-bb0b-15ea2691b2ee"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(original_trades_summary['PnL'], bins=20, kde=False, color='red', label='Original', alpha=0.5)\n",
    "sns.histplot(enhanced_trades_summary['PnL'], bins=20, kde=False, color='blue', label='Enhanced', alpha=0.5)\n",
    "sns.histplot(trade_df['PnL'], bins=20, kde=False, color='green', label='Option C (ML)', alpha=0.5)\n",
    "\n",
    "plt.title('Profit per Trade Distribution Comparison')\n",
    "plt.xlabel('PnL per Trade')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "DQHZoAz0ma-B",
    "outputId": "a01ab61f-4a9b-4566-f363-2bcd9ba4a58e"
   },
   "outputs": [],
   "source": [
    "# Trade Action Timeline Over Portfolio Growth\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_clean['Date'], df_clean['Portfolio_Value'], label='Portfolio Value', color='black')\n",
    "\n",
    "# Map Buy Dates to Portfolio Value on same date\n",
    "buy_portfolio_vals = df_clean.set_index('Date').reindex(pd.to_datetime(trade_df['Buy_Date']))['Portfolio_Value'].values\n",
    "sell_portfolio_vals = df_clean.set_index('Date').reindex(pd.to_datetime(trade_df['Sell_Date']))['Portfolio_Value'].values\n",
    "\n",
    "# BUY markers\n",
    "plt.scatter(pd.to_datetime(trade_df['Buy_Date']), buy_portfolio_vals,\n",
    "            marker='^', color='green', label='BUY', s=100, zorder=5)\n",
    "\n",
    "# SELL markers\n",
    "plt.scatter(pd.to_datetime(trade_df['Sell_Date']), sell_portfolio_vals,\n",
    "            marker='v', color='red', label='SELL', s=100, zorder=5)\n",
    "\n",
    "plt.title('Trade Actions Timeline (Option C - ML Strategy)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "NluNG1optC4i",
    "outputId": "bd80cd56-3918-47f4-c847-d3374573ec72"
   },
   "outputs": [],
   "source": [
    "# End-to-End ML Prediction and Backtesting on New Stock Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ 1. Load New Data\n",
    "df_new = pd.read_csv(\"TRIP_OHLCV_Full_2024_2025.csv\")\n",
    "\n",
    "# ✅ Keep only required columns\n",
    "df_new = df_new[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "# ✅ Convert Date and numeric columns\n",
    "df_new['Date'] = pd.to_datetime(df_new['Date'])\n",
    "for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "    df_new[col] = pd.to_numeric(df_new[col], errors='coerce')\n",
    "\n",
    "# ✅ Drop any rows with NaN\n",
    "df_new.dropna(inplace=True)\n",
    "\n",
    "# ✅ Sort by Date\n",
    "df_new.sort_values('Date', inplace=True)\n",
    "\n",
    "\n",
    "# ✅ 3. Feature Engineering (Same as Training)\n",
    "df_new['Return'] = df_new['Close'].pct_change()\n",
    "df_new['CloseMA_3'] = df_new['Close'].rolling(3).mean()\n",
    "df_new['CloseMA_5'] = df_new['Close'].rolling(5).mean()\n",
    "df_new['CloseMA_10'] = df_new['Close'].rolling(10).mean()\n",
    "\n",
    "# RSI Calculation\n",
    "delta = df_new['Close'].diff()\n",
    "gain = delta.where(delta > 0, 0)\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "avg_gain = gain.rolling(14).mean()\n",
    "avg_loss = loss.rolling(14).mean()\n",
    "rs = avg_gain / avg_loss\n",
    "df_new['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# MACD\n",
    "ema12 = df_new['Close'].ewm(span=12, adjust=False).mean()\n",
    "ema26 = df_new['Close'].ewm(span=26, adjust=False).mean()\n",
    "df_new['MACD'] = ema12 - ema26\n",
    "df_new['MACD_Signal'] = df_new['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# Bollinger Bands\n",
    "df_new['BB_Upper'] = df_new['Close'].rolling(20).mean() + (df_new['Close'].rolling(20).std() * 2)\n",
    "df_new['BB_Lower'] = df_new['Close'].rolling(20).mean() - (df_new['Close'].rolling(20).std() * 2)\n",
    "\n",
    "# Volatility & Volume\n",
    "df_new['Volatility'] = df_new['Return'].rolling(10).std()\n",
    "df_new['Volume_MA'] = df_new['Volume'].rolling(5).mean()\n",
    "\n",
    "# Drop NaN\n",
    "df_new.dropna(inplace=True)\n",
    "\n",
    "# ✅ 4. Define Features (same as model training)\n",
    "feature_cols = [\n",
    "    'CloseMA_3', 'CloseMA_5', 'CloseMA_10',\n",
    "    'RSI', 'MACD', 'MACD_Signal',\n",
    "    'BB_Upper', 'BB_Lower',\n",
    "    'Volatility', 'Return', 'Volume_MA'\n",
    "]\n",
    "\n",
    "X_new = df_new[feature_cols]\n",
    "\n",
    "# ✅ 5. Load the trained model (already in Colab memory)\n",
    "# If your model is named `model` from training, skip loading. Otherwise:\n",
    "# from joblib import load\n",
    "# model = load('model.pkl')   # Not needed if already in session\n",
    "\n",
    "# ✅ 6. Predict Signals\n",
    "df_new['Predicted'] = model.predict(X_new)\n",
    "\n",
    "# Map actions\n",
    "action_map = {'Bullish': 'BUY', 'Bearish': 'SELL', 'Neutral': 'HOLD'}\n",
    "df_new['Action'] = df_new['Predicted'].map(action_map)\n",
    "\n",
    "# ✅ 7. Backtest Portfolio with Predictions\n",
    "initial_capital = 100000\n",
    "position = 0\n",
    "cash = initial_capital\n",
    "portfolio_value = []\n",
    "trade_log = []\n",
    "\n",
    "for i in range(len(df_new)):\n",
    "    price = df_new.iloc[i]['Close']\n",
    "    action = df_new.iloc[i]['Action']\n",
    "    date = df_new.iloc[i]['Date']\n",
    "\n",
    "    if action == 'BUY' and position == 0:\n",
    "        position = cash / price\n",
    "        cash = 0\n",
    "        trade_log.append(('BUY', date, price))\n",
    "    elif action == 'SELL' and position > 0:\n",
    "        cash = position * price\n",
    "        position = 0\n",
    "        trade_log.append(('SELL', date, price))\n",
    "\n",
    "    portfolio_value.append(cash + position * price)\n",
    "\n",
    "df_new['Portfolio_Value'] = portfolio_value\n",
    "final_value = portfolio_value[-1]\n",
    "total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "\n",
    "print(f\"Final Portfolio Value: {final_value:.2f}\")\n",
    "print(f\"Total Return: {total_return:.2f}%\")\n",
    "# print(f\"Number of Trades: {len(trade_log)//2}\")\n",
    "\n",
    "# ✅ 8. Plot Buy/Sell Signals on Price Chart\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(df_new['Date'], df_new['Close'], label='Close Price', color='blue')\n",
    "\n",
    "# Plot Buy signals\n",
    "buy_signals = df_new[df_new['Action'] == 'BUY']\n",
    "sell_signals = df_new[df_new['Action'] == 'SELL']\n",
    "\n",
    "plt.scatter(buy_signals['Date'], buy_signals['Close'], marker='^', color='green', label='Buy Signal', alpha=1)\n",
    "plt.scatter(sell_signals['Date'], sell_signals['Close'], marker='v', color='red', label='Sell Signal', alpha=1)\n",
    "\n",
    "plt.title('ML-Based Buy/Sell Signals')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2M3yRLPYOHw"
   },
   "outputs": [],
   "source": [
    "# Stop-Loss Adjustment on ML Trade Log\n",
    "import pandas as pd\n",
    "\n",
    "# Load necessary data\n",
    "df_price = pd.read_csv(\"enhanced_sentiment_stock_data.csv\")\n",
    "df_price['Date'] = pd.to_datetime(df_price['Date'])\n",
    "df_price.set_index('Date', inplace=True)\n",
    "\n",
    "trade_log = pd.read_excel(\"OptionC_Strategy_Report.xlsx\", sheet_name=\"Trade_Log\")\n",
    "trade_log['Buy_Date'] = pd.to_datetime(trade_log['Buy_Date'])\n",
    "trade_log['Sell_Date'] = pd.to_datetime(trade_log['Sell_Date'])\n",
    "\n",
    "# Parameters\n",
    "stop_loss_pct = 0.10  # 10% stop loss\n",
    "\n",
    "# Create new log with stop-loss applied\n",
    "adjusted_trades = []\n",
    "\n",
    "for _, row in trade_log.iterrows():\n",
    "    buy_date = row['Buy_Date']\n",
    "    sell_date = row['Sell_Date']\n",
    "    buy_price = row['Buy_Price']\n",
    "\n",
    "    try:\n",
    "        price_data = df_price.loc[buy_date:sell_date]['Close']\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "    stop_price = buy_price * (1 - stop_loss_pct)\n",
    "    hit_stop_loss = False\n",
    "\n",
    "    for date, price in price_data.items():\n",
    "        if price <= stop_price:\n",
    "            # Stop-loss hit\n",
    "            adjusted_trades.append({\n",
    "                'Buy_Date': buy_date,\n",
    "                'Buy_Price': buy_price,\n",
    "                'Sell_Date': date,\n",
    "                'Sell_Price': price,\n",
    "                'Stop_Loss_Hit': True\n",
    "            })\n",
    "            hit_stop_loss = True\n",
    "            break\n",
    "\n",
    "    if not hit_stop_loss:\n",
    "        # Normal exit\n",
    "        adjusted_trades.append({\n",
    "            'Buy_Date': buy_date,\n",
    "            'Buy_Price': buy_price,\n",
    "            'Sell_Date': sell_date,\n",
    "            'Sell_Price': row['Sell_Price'],\n",
    "            'Stop_Loss_Hit': False\n",
    "        })\n",
    "\n",
    "df_stoploss = pd.DataFrame(adjusted_trades)\n",
    "df_stoploss.to_excel(\"OptionC_ML_Strategy_StopLoss.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "MQXch_r_Yi4o",
    "outputId": "eedc8aa2-7de0-477d-a798-4a6ced7c23e6"
   },
   "outputs": [],
   "source": [
    "# Random Forest Model Training and Evaluation on Enhanced Sentiment Features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset (used for training)\n",
    "df = pd.read_csv(\"enhanced_sentiment_stock_data.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Features and labels\n",
    "features = ['CloseMA_3', 'CloseMA_5', 'CloseMA_10' ,'RSI', 'MACD', 'BB_Upper', 'BB_Lower']\n",
    "X = df[features]\n",
    "y = df['Sentiment_Enhanced']  # 1 for Bullish, -1 for Bearish, 0 for Neutral\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy scores\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.2f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"Cross-Validation Mean Accuracy: {cv_scores.mean():.2f}\")\n",
    "print(f\"CV Accuracy Std Dev: {cv_scores.std():.2f}\")\n",
    "\n",
    "# Feature importance\n",
    "importances = model.feature_importances_\n",
    "feat_imp = pd.Series(importances, index=features).sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "feat_imp.plot(kind='barh')\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DuXZn9ULbhTi",
    "outputId": "4ae230a6-ee4f-4877-d3dc-d3e710d86c56"
   },
   "outputs": [],
   "source": [
    "# Random Forest Classification with Controlled Complexity on ML Predictions Dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "df_ml = pd.read_csv(\"ml_predictions.csv\")\n",
    "\n",
    "# Step 1: Prepare features and labels\n",
    "features = ['RSI', 'MACD', 'MACD_Signal', 'BB_Upper', 'BB_Lower', 'CloseMA_10', 'CloseMA_5', 'CloseMA_3']\n",
    "X = df_ml[features]\n",
    "y = df_ml['Sentiment_Enhanced']\n",
    "\n",
    "# Step 2: Train-test split (stratify ensures label distribution is preserved)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 3: Build the Random Forest model with restricted complexity\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,               # LIMIT tree depth to avoid overfitting\n",
    "    min_samples_leaf=5,        # Prevent leaves with very few samples\n",
    "    max_features='sqrt',       # Random subset of features for each split\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate on training and test sets\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "# Step 6: Cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "cv_mean = np.mean(cv_scores)\n",
    "cv_std = np.std(cv_scores)\n",
    "\n",
    "# Step 7: Output results\n",
    "print(f\"Train Accuracy: {train_acc:.2f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "print(f\"Cross-Validation Mean Accuracy: {cv_mean:.2f}\")\n",
    "print(f\"CV Accuracy Std Dev: {cv_std:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBSa1moSdQLa"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling Using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4eDYy9qdSvu"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wcf35wjdWPc",
    "outputId": "c206c512-b983-4c58-feea-562c84772f7e"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning of Random Forest Classifier Using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3, 5],\n",
    "    'min_samples_leaf': [5],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "grid.fit(X_scaled, y)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best Cross-Val Accuracy:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "TjqE_hMZeFdw",
    "outputId": "e02726b5-611c-42d7-fde5-ae7298b0da6f"
   },
   "outputs": [],
   "source": [
    "# Plotting Feature Importances of the Trained Random Forest Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = model.feature_importances_\n",
    "plt.barh(features, importances)\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlfAMBb6eKtM",
    "outputId": "0db71f3f-e41d-49b9-8caa-516c3e9cbefa"
   },
   "outputs": [],
   "source": [
    "# Training and Evaluating Logistic Regression Model on Stock Sentiment Data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"LogReg Test Accuracy:\", logreg.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSMJCYT3ewe3",
    "outputId": "0510e8ac-3633-40f5-8538-f67d5feb6dd2"
   },
   "outputs": [],
   "source": [
    "# Train and Evaluate Optimized Random Forest Classifier with Classification Report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# 2. Best model from GridSearch\n",
    "best_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. Fit model\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate\n",
    "print(\"Train Accuracy:\", best_model.score(X_train, y_train))\n",
    "print(\"Test Accuracy:\", best_model.score(X_test, y_test))\n",
    "\n",
    "# 5. Detailed report\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXkT7mJJmYGU"
   },
   "outputs": [],
   "source": [
    "# Train Best Random Forest Model and Predict Labels on Full Dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Best parameters from GridSearchCV\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "df['ML_Label'] = best_rf.predict(X_scaled)  # predictions for the full dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fp56A56NmbAC"
   },
   "outputs": [],
   "source": [
    "# Map Predicted Sentiment Labels to Trading Actions (Buy, Sell, Hold)\n",
    "label_to_action = {\n",
    "    'Bullish': 'Buy',\n",
    "    'Bearish': 'Sell',\n",
    "    'Neutral': 'Hold'\n",
    "}\n",
    "df['ML_Action'] = df['ML_Label'].map(label_to_action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxSkNktlmeBy"
   },
   "outputs": [],
   "source": [
    "# Backtesting ML-Based Trading Strategy with 2% Stop-Loss and Portfolio Value Tracking\n",
    "initial_capital = 100000\n",
    "position = 0\n",
    "capital = initial_capital\n",
    "entry_price = None\n",
    "portfolio_values = []\n",
    "\n",
    "stop_loss_pct = 0.02  # 2% stop loss\n",
    "\n",
    "for i in range(len(df)):\n",
    "    action = df.iloc[i]['ML_Action']\n",
    "    price = df.iloc[i]['Close']\n",
    "\n",
    "    if action == 'Buy' and position == 0:\n",
    "        position = capital / price\n",
    "        entry_price = price\n",
    "        capital = 0\n",
    "\n",
    "    elif action == 'Sell' and position > 0:\n",
    "        capital = position * price\n",
    "        position = 0\n",
    "        entry_price = None\n",
    "\n",
    "    # Stop-loss trigger\n",
    "    if position > 0 and (price < entry_price * (1 - stop_loss_pct)):\n",
    "        capital = position * price\n",
    "        position = 0\n",
    "        entry_price = None\n",
    "\n",
    "    portfolio_values.append(capital + (position * price if position > 0 else 0))\n",
    "\n",
    "df['ML_Portfolio'] = portfolio_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sIuFLL1n1fi"
   },
   "outputs": [],
   "source": [
    "# Function for Simple Sentiment-Based Backtesting to Calculate Portfolio Growth\n",
    "def backtest_strategy(df, sentiment_col, portfolio_col):\n",
    "    df[portfolio_col] = 1.0\n",
    "    position = 0\n",
    "    for i in range(1, len(df)):\n",
    "        if df[sentiment_col].iloc[i-1] == 'Bullish':\n",
    "            position = 1\n",
    "        elif df[sentiment_col].iloc[i-1] == 'Bearish':\n",
    "            position = -1\n",
    "        else:\n",
    "            position = 0\n",
    "        df.loc[df.index[i], portfolio_col] = df[portfolio_col].iloc[i-1] * (1 + position * df['Return'].iloc[i])\n",
    "    return df\n",
    "\n",
    "# Run for original and enhanced\n",
    "df = backtest_strategy(df, 'Sentiment', 'Original_Portfolio')\n",
    "df = backtest_strategy(df, 'Sentiment_Enhanced', 'Enhanced_Portfolio')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "F20ncSMQnPSW",
    "outputId": "3fe386ae-ff78-4e77-fa55-31c43f84b398"
   },
   "outputs": [],
   "source": [
    "# Plot Portfolio Value Comparison for Original, Enhanced, and ML Strategies\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df['Date'], df['Original_Portfolio'], label='Original Sentiment')\n",
    "plt.plot(df['Date'], df['Enhanced_Portfolio'], label='Enhanced Sentiment')\n",
    "plt.plot(df['Date'], df['ML_Portfolio'], label='ML w/ Stop-Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Strategy Portfolio Comparison\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6aAZGA_oEXM",
    "outputId": "e29a100d-009d-49e5-d707-2cb6d604224d"
   },
   "outputs": [],
   "source": [
    "# Calculate and Display Final Return and Win Rate for ML Strategy\n",
    "ml_return = (df['ML_Portfolio'].iloc[-1] - initial_capital) / initial_capital * 100\n",
    "print(f\"ML Strategy Final Return: {ml_return:.2f}%\")\n",
    "\n",
    "# Win rate calculation\n",
    "df['Trade_Return'] = df['Close'].pct_change()\n",
    "win_rate = (df['Trade_Return'] > 0).mean() * 100\n",
    "print(f\"ML Strategy Win Rate: {win_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aw6hR00fu1uf",
    "outputId": "ab74299c-6b12-4ddd-ccc3-86c20f497715"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"OptionC_ML_Strategy_StopLoss.xlsx\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noJq2rZ_x3sM",
    "outputId": "f8ac48fa-bb14-4732-ae0f-5f4bd7fabc82"
   },
   "outputs": [],
   "source": [
    "!pip install mplfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "8zO1mVKBxqsw",
    "outputId": "d4d466ea-2f3d-4d9e-b458-0a70dd97f58e"
   },
   "outputs": [],
   "source": [
    "# Plot Candlestick Chart with Buy/Sell Markers for ML Strategy Trades (Including Stop-Loss)\n",
    "import pandas as pd\n",
    "import mplfinance as mpf\n",
    "\n",
    "# --- Load and clean OHLC data ---\n",
    "# Replace with your actual OHLC CSV file path\n",
    "price_df = pd.read_csv(\"TRIP_OHLCV_Full_2024_2025.csv\")\n",
    "\n",
    "# Ensure Date is datetime and set as index\n",
    "price_df['Date'] = pd.to_datetime(price_df['Date'], errors='coerce')\n",
    "price_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Convert OHLC to numeric and drop rows with invalid prices\n",
    "for col in ['Open', 'High', 'Low', 'Close']:\n",
    "    price_df[col] = pd.to_numeric(price_df[col], errors='coerce')\n",
    "price_df.dropna(subset=['Open', 'High', 'Low', 'Close'], inplace=True)\n",
    "\n",
    "# Ensure Volume is numeric if present\n",
    "if 'Volume' in price_df.columns:\n",
    "    price_df['Volume'] = pd.to_numeric(price_df['Volume'], errors='coerce').fillna(0)\n",
    "\n",
    "# --- Load ML trades ---\n",
    "ml_trades = pd.read_excel(\"OptionC_ML_Strategy_StopLoss.xlsx\")  # Has Buy_Date, Buy_Price, Sell_Date, Sell_Price, Stop_Loss_Hit\n",
    "ml_trades['Buy_Date'] = pd.to_datetime(ml_trades['Buy_Date'], errors='coerce')\n",
    "ml_trades['Sell_Date'] = pd.to_datetime(ml_trades['Sell_Date'], errors='coerce')\n",
    "\n",
    "# --- Prepare Buy/Sell markers ---\n",
    "buy_markers = pd.Series(index=price_df.index, dtype=float)\n",
    "sell_markers = pd.Series(index=price_df.index, dtype=float)\n",
    "\n",
    "for _, trade in ml_trades.iterrows():\n",
    "    if trade['Buy_Date'] in buy_markers.index:\n",
    "        buy_markers.loc[trade['Buy_Date']] = trade['Buy_Price']\n",
    "    if trade['Sell_Date'] in sell_markers.index:\n",
    "        sell_markers.loc[trade['Sell_Date']] = trade['Sell_Price']\n",
    "\n",
    "# --- Create addplots ---\n",
    "apds = []\n",
    "if not buy_markers.dropna().empty:\n",
    "    apds.append(mpf.make_addplot(buy_markers, type='scatter', markersize=100, marker='^', color='g'))\n",
    "if not sell_markers.dropna().empty:\n",
    "    apds.append(mpf.make_addplot(sell_markers, type='scatter', markersize=100, marker='v', color='r'))\n",
    "\n",
    "# --- Plot ---\n",
    "mpf.plot(\n",
    "    price_df,\n",
    "    type='candle',\n",
    "    style='yahoo',\n",
    "    addplot=apds,\n",
    "    title=\"ML Stop-loss Strategy Trades\",\n",
    "    ylabel=\"Price\",\n",
    "    volume=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "id": "Cep21yjKZRZM",
    "outputId": "077f9e31-35f2-43f6-d812-00f6f14afe14"
   },
   "outputs": [],
   "source": [
    "# Plot ML Strategy Trades on Close Price with Buy, Sell, and Stop-Loss Markers (Aligned to Nearest Market Dates)\n",
    "# Plot ML + Stop-loss trades on Close price (line plot + markers)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "PRICE_FILE = \"enhanced_sentiment_stock_data.csv\"            # your OHLC file (CSV or XLSX)\n",
    "TRADES_FILE = \"OptionC_ML_Strategy_StopLoss.xlsx\"      # trades file with Buy_Date, Buy_Price, Sell_Date, Sell_Price, Stop_Loss_Hit\n",
    "PRICE_SHEET = None   # if price is Excel, set sheet name string, else None\n",
    "TRADES_SHEET = None  # if trades file has multiple sheets, set the correct sheet name\n",
    "DATE_COL_PRICE = \"Date\"\n",
    "CLOSE_COL = \"Close\"\n",
    "# ----------------------------\n",
    "\n",
    "# --- 1) Load price data robustly (CSV or Excel) ---\n",
    "import os\n",
    "name, ext = os.path.splitext(PRICE_FILE)\n",
    "if ext.lower() in [\".xlsx\", \".xls\"]:\n",
    "    price_df = pd.read_excel(PRICE_FILE, sheet_name=PRICE_SHEET)\n",
    "else:\n",
    "    price_df = pd.read_csv(PRICE_FILE)\n",
    "\n",
    "# Clean and prepare price_df\n",
    "price_df[DATE_COL_PRICE] = pd.to_datetime(price_df[DATE_COL_PRICE], errors=\"coerce\")\n",
    "price_df = price_df.dropna(subset=[DATE_COL_PRICE]).copy()\n",
    "price_df.set_index(DATE_COL_PRICE, inplace=True)\n",
    "# ensure Close numeric\n",
    "price_df[CLOSE_COL] = pd.to_numeric(price_df[CLOSE_COL], errors=\"coerce\")\n",
    "price_df.dropna(subset=[CLOSE_COL], inplace=True)\n",
    "\n",
    "# --- 2) Load trades (ML stop-loss) ---\n",
    "trades = pd.read_excel(\"OptionC_ML_Strategy_StopLoss.xlsx\")  # excel assumed, change to read_csv if necessary\n",
    "# Required columns: Buy_Date, Buy_Price, Sell_Date, Sell_Price, Stop_Loss_Hit (boolean/0-1)\n",
    "price_df.sort_index(inplace=True)\n",
    "print(price_df.head(), price_df.index.min(), price_df.index.max())\n",
    "\n",
    "for c in [\"Buy_Date\",\"Sell_Date\"]:\n",
    "    if c in trades.columns:\n",
    "        trades[c] = pd.to_datetime(trades[c], errors=\"coerce\")\n",
    "\n",
    "# If Stop_Loss_Hit is not boolean, make it:\n",
    "if \"Stop_Loss_Hit\" in trades.columns:\n",
    "    trades[\"Stop_Loss_Hit\"] = trades[\"Stop_Loss_Hit\"].astype(bool)\n",
    "else:\n",
    "    trades[\"Stop_Loss_Hit\"] = False\n",
    "\n",
    "# --- 3) Align trade dates to available price index (nearest) ---\n",
    "# Create empty marker series aligned with price_df index\n",
    "buy_markers = pd.Series(index=price_df.index, dtype=float)\n",
    "sell_markers = pd.Series(index=price_df.index, dtype=float)\n",
    "stop_markers = pd.Series(index=price_df.index, dtype=float)\n",
    "\n",
    "price_index = price_df.index\n",
    "\n",
    "def align_to_nearest_market_date(dt):\n",
    "    \"\"\"Return nearest index entry for a trade datetime dt; returns None if price_index is empty.\"\"\"\n",
    "    if pd.isna(dt):\n",
    "        return None\n",
    "    try:\n",
    "        # get_loc with method='nearest'\n",
    "        pos = price_index.get_loc(dt, method=\"nearest\")\n",
    "        return price_index[pos]\n",
    "    except Exception:\n",
    "        # fallback: find smallest absolute delta\n",
    "        diffs = abs((price_index - dt))\n",
    "        if len(diffs)==0:\n",
    "            return None\n",
    "        return price_index[diffs.argmin()]\n",
    "\n",
    "for _, row in trades.iterrows():\n",
    "    # Align buy\n",
    "    bd = row.get(\"Buy_Date\", pd.NaT)\n",
    "    sd = row.get(\"Sell_Date\", pd.NaT)\n",
    "    a_bd = align_to_nearest_market_date(bd)\n",
    "    a_sd = align_to_nearest_market_date(sd)\n",
    "    if a_bd is not None:\n",
    "        buy_markers.loc[a_bd] = row.get(\"Buy_Price\", price_df.loc[a_bd, CLOSE_COL] if a_bd in price_df.index else None)\n",
    "    if a_sd is not None:\n",
    "        sell_markers.loc[a_sd] = row.get(\"Sell_Price\", price_df.loc[a_sd, CLOSE_COL] if a_sd in price_df.index else None)\n",
    "    # stop-loss marker if hit\n",
    "    if row.get(\"Stop_Loss_Hit\", False) and a_sd is not None:\n",
    "        stop_markers.loc[a_sd] = row.get(\"Sell_Price\", price_df.loc[a_sd, CLOSE_COL] if a_sd in price_df.index else None)\n",
    "\n",
    "# --- 4) Zoom window around trades (min/max trade dates ± padding) ---\n",
    "trade_dates = pd.to_datetime(trades[[\"Buy_Date\",\"Sell_Date\"]].values.ravel(), errors=\"coerce\")\n",
    "trade_dates = trade_dates[~pd.isna(trade_dates)]\n",
    "if len(trade_dates) > 0:\n",
    "    start = trade_dates.min() - timedelta(days=3)\n",
    "    end = trade_dates.max() + timedelta(days=3)\n",
    "    price_plot = price_df.loc[start:end]\n",
    "else:\n",
    "    price_plot = price_df.copy()  # no trades found; plot whole range\n",
    "\n",
    "# --- 5) Plot (Close price line + markers) ---\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(price_plot.index, price_plot[CLOSE_COL], label=\"Close Price\", color=\"black\")\n",
    "\n",
    "# Draw markers only where non-null\n",
    "if buy_markers.dropna().size > 0:\n",
    "    bm = buy_markers.reindex(price_plot.index)\n",
    "    plt.scatter(bm.index[bm.notna()], bm.dropna().values, marker=\"^\", color=\"green\", s=100, label=\"BUY\", zorder=5)\n",
    "\n",
    "if sell_markers.dropna().size > 0:\n",
    "    sm = sell_markers.reindex(price_plot.index)\n",
    "    plt.scatter(sm.index[sm.notna()], sm.dropna().values, marker=\"v\", color=\"red\", s=100, label=\"SELL\", zorder=5)\n",
    "\n",
    "if stop_markers.dropna().size > 0:\n",
    "    xm = stop_markers.reindex(price_plot.index)\n",
    "    plt.scatter(xm.index[xm.notna()], xm.dropna().values, marker=\"x\", color=\"orange\", s=120, label=\"STOP-LOSS\", zorder=6)\n",
    "\n",
    "plt.title(\"ML Strategy Trades (Stop-loss) — Close price with trade markers\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "id": "iXKfdunx5ZdT",
    "outputId": "03e4a260-5a87-4e2b-b6e4-30bc17374893"
   },
   "outputs": [],
   "source": [
    "# Plot Close Price with Buy, Sell, and Stop-Loss Markers for ML Strategy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# --- Ensure correct column and index ---\n",
    "CLOSE_COL = \"Close\"\n",
    "price_df = price_df.sort_index()\n",
    "price_df[CLOSE_COL] = pd.to_numeric(price_df[CLOSE_COL], errors='coerce')\n",
    "\n",
    "# --- Debug: Check value ranges before plotting ---\n",
    "print(\"Close min/max:\", price_df[CLOSE_COL].min(), price_df[CLOSE_COL].max())\n",
    "\n",
    "# Align trades to nearest market dates\n",
    "def align_to_nearest_market_date(trade_dates, market_dates):\n",
    "    aligned_dates = []\n",
    "    for date in trade_dates:\n",
    "        diffs = abs(market_dates - date)\n",
    "        nearest_idx = diffs.argmin()\n",
    "        aligned_dates.append(market_dates[nearest_idx])\n",
    "    return aligned_dates\n",
    "\n",
    "\n",
    "buy_dates = align_to_nearest_market_date(trades[\"Buy_Date\"], price_df.index)\n",
    "sell_dates = align_to_nearest_market_date(trades[\"Sell_Date\"], price_df.index)\n",
    "# --- Buy & Sell markers ---\n",
    "buy_markers = price_df.loc[buy_dates, CLOSE_COL]\n",
    "sell_markers = price_df.loc[sell_dates, CLOSE_COL]\n",
    "\n",
    "# Ensure Sell_Date is datetime and normalized (remove time part)\n",
    "stop_loss_dates = pd.to_datetime(\n",
    "    trades.loc[trades[\"Stop_Loss_Hit\"] == 1, \"Sell_Date\"]\n",
    ").dt.normalize()\n",
    "\n",
    "# Convert to index for intersection\n",
    "stop_loss_dates = pd.Index(stop_loss_dates)\n",
    "\n",
    "# Now intersect to avoid KeyError\n",
    "stop_loss_dates = stop_loss_dates.intersection(price_df.index)\n",
    "\n",
    "# --- Stop-loss markers (align using Sell_Date) ---\n",
    "# Ensure index is datetime\n",
    "price_df.index = pd.to_datetime(price_df.index).normalize()\n",
    "\n",
    "# Ensure Sell_Date is datetime and normalized (remove time part)\n",
    "stop_loss_dates = pd.to_datetime(\n",
    "    trades.loc[trades[\"Stop_Loss_Hit\"] == 1, \"Sell_Date\"]\n",
    ").dt.normalize()\n",
    "\n",
    "# Now intersect to avoid KeyError\n",
    "stop_loss_dates = pd.DatetimeIndex(stop_loss_dates.unique()).intersection(price_df.index)\n",
    "\n",
    "\n",
    "# Get stop-loss markers\n",
    "stop_loss_markers = price_df.loc[stop_loss_dates, CLOSE_COL]\n",
    "\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(price_df.index, price_df[CLOSE_COL], label=\"Close Price\", color=\"blue\")\n",
    "\n",
    "# Buy markers\n",
    "plt.scatter(buy_markers.index, buy_markers, marker=\"^\", color=\"green\", s=100, label=\"Buy Signal\")\n",
    "\n",
    "# Sell markers\n",
    "plt.scatter(sell_markers.index, sell_markers, marker=\"v\", color=\"red\", s=100, label=\"Sell Signal\")\n",
    "\n",
    "# Stop-loss markers\n",
    "plt.scatter(stop_loss_markers.index, stop_loss_markers, marker=\"x\", color=\"black\", s=100, label=\"Stop Loss Hit\")\n",
    "\n",
    "plt.title(\"ML Strategy with Stop-Loss\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbH3TPIZDytO",
    "outputId": "ee841f60-bfae-46d4-e7fb-2d14b8e16d1c"
   },
   "outputs": [],
   "source": [
    "# --- DEBUG INFO: Inspect Price Index, Trade Dates, and Marker Counts for Plotting Alignment ---\n",
    "\n",
    "print(\"Price index sample:\", price_df.index[:5])\n",
    "print(\"Buy dates before intersection:\", trades[\"Buy_Date\"].unique())\n",
    "print(\"Sell dates before intersection:\", trades[\"Sell_Date\"].unique())\n",
    "\n",
    "print(\"Buy markers count:\", len(buy_markers))\n",
    "print(\"Sell markers count:\", len(sell_markers))\n",
    "print(\"Stop loss markers count:\", len(stop_loss_markers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEgYeIonHWKk",
    "outputId": "3d9c8a63-2505-45ab-d910-b9846b830ef5"
   },
   "outputs": [],
   "source": [
    "# --- Extract and Display Trades Where Stop-Loss Was Hit ---\n",
    "\n",
    "stop_loss_hits = trades[trades[\"Stop_Loss_Hit\"] == 1][[\"Sell_Date\", \"Sell_Price\"]]\n",
    "print(stop_loss_hits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lDG41K2Kj3g",
    "outputId": "43d097df-7576-4cc6-e5cb-bf14ec369284"
   },
   "outputs": [],
   "source": [
    "# Step1: Comparative metrics for Original / Enhanced / ML+StopLoss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "# ---------- CONFIG - set filepaths if you used files ----------\n",
    "# If you already have the portfolio Series in a DataFrame 'df' use the columns names below.\n",
    "# Otherwise, set file paths to read the portfolio curves and trade logs.\n",
    "PRICE_PORTFOLIO_DF = None   # e.g. \"All_Strategies_Report.xlsx\" if you saved portfolio curves there\n",
    "# Trade logs (optional) - adapt names to your files\n",
    "ORIG_TRADES_FILE = \"trades_sentiment.csv\"               # or None\n",
    "ENH_TRADES_FILE  = \"trades_sentiment_enhanced.csv\"      # or None\n",
    "ML_TRADES_FILE   = \"OptionC_ML_Strategy_StopLoss.xlsx\"  # this should contain Buy/Sell columns and Stop_Loss_Hit\n",
    "# If you already have everything in memory (df with portfolio columns), set USE_IN_MEMORY=True\n",
    "USE_IN_MEMORY = True\n",
    "\n",
    "# If using in-memory DataFrame created earlier in notebook, it should be `df`\n",
    "# and contain columns: 'Original_Portfolio', 'Enhanced_Portfolio', 'ML_Portfolio'\n",
    "# and trade logs (optionally) in variables original_trades_df, enhanced_trades_df, ml_trades_df\n",
    "# If not, set USE_IN_MEMORY=False and the code will try to read CSV/Excel files instead.\n",
    "\n",
    "initial_capital = 100000.0\n",
    "\n",
    "# -------------------- helper functions --------------------\n",
    "def ensure_series(s):\n",
    "    s = s.dropna().copy()\n",
    "    s.index = pd.to_datetime(s.index)\n",
    "    s = s.sort_index()\n",
    "    # If the series looks like a factor (starting near 1), scale to initial capital\n",
    "    if s.max() < 10:\n",
    "        s = s * initial_capital\n",
    "    return s\n",
    "\n",
    "def compute_portfolio_metrics(portfolio_series, initial_capital=initial_capital):\n",
    "    s = ensure_series(portfolio_series)\n",
    "    final_value = float(s.iloc[-1])\n",
    "    total_return_pct = (final_value - initial_capital)/initial_capital * 100\n",
    "    days = (s.index[-1] - s.index[0]).days\n",
    "    years = days / 365.25 if days > 0 else 1/252\n",
    "    cagr_pct = ((final_value / initial_capital) ** (1/years) - 1) * 100 if years>0 else np.nan\n",
    "    daily_returns = s.pct_change().dropna()\n",
    "    sharpe = (daily_returns.mean() / daily_returns.std() * np.sqrt(252)) if daily_returns.std() != 0 else 0.0\n",
    "    rolling_max = s.cummax()\n",
    "    drawdown = (s - rolling_max) / rolling_max\n",
    "    max_dd_pct = drawdown.min() * 100\n",
    "    return {\n",
    "        \"Final Value\": final_value,\n",
    "        \"Total Return (%)\": total_return_pct,\n",
    "        \"CAGR (%)\": cagr_pct,\n",
    "        \"Sharpe Ratio\": sharpe,\n",
    "        \"Max Drawdown (%)\": max_dd_pct,\n",
    "        \"Data Points\": len(s)\n",
    "    }\n",
    "\n",
    "def reconstruct_trades_from_log(trades_df):\n",
    "    \"\"\"\n",
    "    Accepts either:\n",
    "      - DataFrame with columns [Buy_Date, Buy_Price, Sell_Date, Sell_Price, Stop_Loss_Hit (opt)]\n",
    "      - Action log DataFrame with ['Date','Action','Price','Shares'(opt)]\n",
    "    Returns a DataFrame with Buy/Sell trades and PnL/holding days.\n",
    "    \"\"\"\n",
    "    if trades_df is None:\n",
    "        return pd.DataFrame()\n",
    "    df = trades_df.copy()\n",
    "    cols = [c.lower() for c in df.columns]\n",
    "    # Case 1: Buy/Sell pairs present\n",
    "    if set(['buy_date','sell_date']).issubset(cols):\n",
    "        # normalize column names\n",
    "        col_map = {c:c for c in df.columns}\n",
    "        # attempt to standardize names:\n",
    "        # find exact column names for required fields\n",
    "        def find_col_like(name):\n",
    "            for c in df.columns:\n",
    "                if c.lower()==name:\n",
    "                    return c\n",
    "            return None\n",
    "        bcol = find_col_like('buy_date'); scol = find_col_like('sell_date')\n",
    "        bpcol = find_col_like('buy_price') or find_col_like('buy') or find_col_like('buyprice')\n",
    "        spcol = find_col_like('sell_price') or find_col_like('sell') or find_col_like('sellprice')\n",
    "        df[bcol] = pd.to_datetime(df[bcol], errors='coerce')\n",
    "        df[scol] = pd.to_datetime(df[scol], errors='coerce')\n",
    "        # compute pnl if prices exist\n",
    "        if bpcol and spcol:\n",
    "            df['PnL'] = pd.to_numeric(df[spcol], errors='coerce') - pd.to_numeric(df[bpcol], errors='coerce')\n",
    "            df['Return_%'] = df['PnL'] / pd.to_numeric(df[bpcol], errors='coerce') * 100\n",
    "        df['Holding_Days'] = (df[scol] - df[bcol]).dt.days\n",
    "        # rename for consistent output\n",
    "        out_cols = {}\n",
    "        out_cols[bcol] = 'Buy_Date'\n",
    "        out_cols[scol] = 'Sell_Date'\n",
    "        if bpcol: out_cols[bpcol] = 'Buy_Price'\n",
    "        if spcol: out_cols[spcol] = 'Sell_Price'\n",
    "        df = df.rename(columns=out_cols)\n",
    "        # keep Stop_Loss_Hit if exists\n",
    "        keep = ['Buy_Date','Buy_Price','Sell_Date','Sell_Price','PnL','Return_%','Holding_Days']\n",
    "        for k in ['Stop_Loss_Hit','Stop_Loss','StopLoss']:\n",
    "            if k in df.columns and 'Stop_Loss_Hit' not in df.columns:\n",
    "                df['Stop_Loss_Hit'] = df[k].astype(bool)\n",
    "        for c in keep:\n",
    "            if c not in df.columns:\n",
    "                df[c] = np.nan\n",
    "        return df[keep + (['Stop_Loss_Hit'] if 'Stop_Loss_Hit' in df.columns else [])]\n",
    "    # Case 2: Action log with Buy/Sell rows\n",
    "    if 'action' in cols or 'price' in cols:\n",
    "        # unify names\n",
    "        cdate = None\n",
    "        for c in df.columns:\n",
    "            if c.lower() == 'date': cdate = c\n",
    "        if cdate is None:\n",
    "            raise ValueError(\"Action log format requires a Date column.\")\n",
    "        df[cdate] = pd.to_datetime(df[cdate], errors='coerce')\n",
    "        # find action and price columns\n",
    "        action_col = [c for c in df.columns if c.lower()=='action'][0]\n",
    "        price_col = [c for c in df.columns if c.lower() in ('price','close','adjclose')][0]\n",
    "        trades = []\n",
    "        current = None\n",
    "        for _, r in df.iterrows():\n",
    "            act = str(r[action_col]).strip().lower()\n",
    "            if act == 'buy' and current is None:\n",
    "                current = {'Buy_Date': r[cdate], 'Buy_Price': float(r[price_col])}\n",
    "            elif act == 'sell' and current is not None:\n",
    "                current['Sell_Date'] = r[cdate]; current['Sell_Price']=float(r[price_col])\n",
    "                current['PnL'] = current['Sell_Price'] - current['Buy_Price']\n",
    "                current['Return_%'] = current['PnL']/current['Buy_Price']*100\n",
    "                current['Holding_Days'] = (current['Sell_Date'] - current['Buy_Date']).days\n",
    "                trades.append(current); current=None\n",
    "        if len(trades)==0:\n",
    "            return pd.DataFrame()\n",
    "        return pd.DataFrame(trades)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def trade_statistics(trades_df):\n",
    "    if trades_df is None or trades_df.empty:\n",
    "        return {\n",
    "            \"Number of Trades\": 0,\n",
    "            \"Win Rate (%)\": np.nan,\n",
    "            \"Avg PnL\": np.nan,\n",
    "            \"Median Holding (days)\": np.nan,\n",
    "            \"Stop Loss Hits\": 0\n",
    "        }\n",
    "    t = trades_df.copy()\n",
    "    # ensure cols\n",
    "    if 'Buy_Date' in t.columns: t['Buy_Date'] = pd.to_datetime(t['Buy_Date'], errors='coerce')\n",
    "    if 'Sell_Date' in t.columns: t['Sell_Date'] = pd.to_datetime(t['Sell_Date'], errors='coerce')\n",
    "    if 'PnL' not in t.columns and ('Buy_Price' in t.columns and 'Sell_Price' in t.columns):\n",
    "        t['PnL'] = pd.to_numeric(t['Sell_Price'], errors='coerce') - pd.to_numeric(t['Buy_Price'], errors='coerce')\n",
    "    if 'Return_%' not in t.columns and 'PnL' in t.columns and 'Buy_Price' in t.columns:\n",
    "        t['Return_%'] = t['PnL'] / pd.to_numeric(t['Buy_Price'], errors='coerce') * 100\n",
    "    if 'Holding_Days' not in t.columns and 'Sell_Date' in t.columns and 'Buy_Date' in t.columns:\n",
    "        t['Holding_Days'] = (t['Sell_Date'] - t['Buy_Date']).dt.days\n",
    "    num = len(t)\n",
    "    win_rate = (t['PnL'] > 0).mean() * 100 if 'PnL' in t.columns else np.nan\n",
    "    avg_pnl = t['PnL'].mean() if 'PnL' in t.columns else np.nan\n",
    "    median_h = t['Holding_Days'].median() if 'Holding_Days' in t.columns else np.nan\n",
    "    stop_hits = int(t['Stop_Loss_Hit'].sum()) if 'Stop_Loss_Hit' in t.columns else 0\n",
    "    return {\n",
    "        \"Number of Trades\": int(num),\n",
    "        \"Win Rate (%)\": float(win_rate),\n",
    "        \"Avg PnL\": float(avg_pnl) if not pd.isna(avg_pnl) else np.nan,\n",
    "        \"Median Holding (days)\": float(median_h) if not pd.isna(median_h) else np.nan,\n",
    "        \"Stop Loss Hits\": stop_hits\n",
    "    }\n",
    "\n",
    "# -------------------- load data (either in-memory df or file-based) --------------------\n",
    "if USE_IN_MEMORY:\n",
    "    # assumes 'df' exists with portfolio columns\n",
    "    try:\n",
    "        df  # if df not defined this will raise\n",
    "    except NameError:\n",
    "        raise RuntimeError(\"USE_IN_MEMORY=True but no DataFrame 'df' found in the notebook. Set USE_IN_MEMORY=False and point to files.\")\n",
    "    # possible column names\n",
    "    portfolio_map = {}\n",
    "    # try common names\n",
    "    if 'Original_Portfolio' in df.columns:\n",
    "        portfolio_map['Original'] = df['Original_Portfolio']\n",
    "    if 'Enhanced_Portfolio' in df.columns:\n",
    "        portfolio_map['Enhanced'] = df['Enhanced_Portfolio']\n",
    "    # try older name\n",
    "    if 'Portfolio_Value_Improved' in df.columns and 'Enhanced' not in portfolio_map:\n",
    "        portfolio_map['Enhanced'] = df['Portfolio_Value_Improved']\n",
    "    if 'Portfolio_Value' in df.columns and 'Original' not in portfolio_map:\n",
    "        # ambiguous, only use if it's clearly original\n",
    "        portfolio_map.setdefault('Original', df['Portfolio_Value'])\n",
    "    # ML portfolio\n",
    "    if 'ML_Portfolio' in df.columns:\n",
    "        portfolio_map['ML (StopLoss)'] = df['ML_Portfolio']\n",
    "    elif 'Portfolio_Value_OptionC' in df.columns:\n",
    "        portfolio_map['ML (StopLoss)'] = df['Portfolio_Value_OptionC']\n",
    "    # trade logs (if in-memory)\n",
    "    original_trades_df = globals().get('original_trades', None)\n",
    "    if original_trades_df is None:\n",
    "        original_trades_df = globals().get('original_trades_summary', None)\n",
    "\n",
    "    enhanced_trades_df = globals().get('enhanced_trades', None)\n",
    "    if enhanced_trades_df is None:\n",
    "        enhanced_trades_df = globals().get('enhanced_trades_summary', None)\n",
    "\n",
    "    ml_trades_df = globals().get('trade_df', None)\n",
    "    if ml_trades_df is None:\n",
    "        ml_trades_df = globals().get('ml_trades', None)\n",
    "\n",
    "else:\n",
    "    # load from files if provided (best-effort)\n",
    "    portfolio_map = {}\n",
    "    if os.path.exists(\"Original_Portfolio.csv\"):\n",
    "        p = pd.read_csv(\"Original_Portfolio.csv\", parse_dates=['Date'], index_col='Date')\n",
    "        portfolio_map['Original'] = p.iloc[:,0]\n",
    "    if PRICE_PORTFOLIO_DF and os.path.exists(PRICE_PORTFOLIO_DF):\n",
    "        tmp = pd.read_excel(PRICE_PORTFOLIO_DF, sheet_name=None)\n",
    "        # try to pick sheets/columns heuristically\n",
    "        for name, sheet in tmp.items():\n",
    "            if 'Portfolio' in sheet.columns[0] or 'Portfolio' in str(sheet.columns):\n",
    "                for c in sheet.columns:\n",
    "                    if 'Portfolio' in c:\n",
    "                        portfolio_map[name] = sheet[c]\n",
    "    # load trade files if available\n",
    "    original_trades_df = pd.read_csv(ORIG_TRADES_FILE) if ORIG_TRADES_FILE and os.path.exists(ORIG_TRADES_FILE) else None\n",
    "    enhanced_trades_df  = pd.read_csv(ENH_TRADES_FILE) if ENH_TRADES_FILE and os.path.exists(ENH_TRADES_FILE) else None\n",
    "    if ML_TRADES_FILE and os.path.exists(ML_TRADES_FILE):\n",
    "        if ML_TRADES_FILE.lower().endswith('.csv'):\n",
    "            ml_trades_df = pd.read_csv(ML_TRADES_FILE)\n",
    "        else:\n",
    "            ml_trades_df = pd.read_excel(ML_TRADES_FILE)\n",
    "    else:\n",
    "        ml_trades_df = None\n",
    "\n",
    "# --------------- compute metrics for each available portfolio ---------------\n",
    "results = []\n",
    "trade_summaries = {}\n",
    "\n",
    "for name, series in portfolio_map.items():\n",
    "    metrics = compute_portfolio_metrics(series)\n",
    "    # attach trade stats if trade log matches name\n",
    "    if name.startswith('Original') and original_trades_df is not None:\n",
    "        trades_parsed = reconstruct_trades_from_log(original_trades_df)\n",
    "        ts = trade_statistics(trades_parsed)\n",
    "        trade_summaries[name] = trades_parsed\n",
    "    elif name.startswith('Enhanced') and enhanced_trades_df is not None:\n",
    "        trades_parsed = reconstruct_trades_from_log(enhanced_trades_df)\n",
    "        ts = trade_statistics(trades_parsed)\n",
    "        trade_summaries[name] = trades_parsed\n",
    "    else:\n",
    "        # if ml or no logs available, try ml_trades_df\n",
    "        if ml_trades_df is not None and 'ML' in name:\n",
    "            trades_parsed = reconstruct_trades_from_log(ml_trades_df)\n",
    "            ts = trade_statistics(trades_parsed)\n",
    "            trade_summaries[name] = trades_parsed\n",
    "        else:\n",
    "            ts = trade_statistics(pd.DataFrame())\n",
    "    # combine\n",
    "    combined = {**{\"Strategy\": name}, **metrics, **ts}\n",
    "    results.append(combined)\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "# reorder columns for readability\n",
    "cols_order = [\"Strategy\",\"Final Value\",\"Total Return (%)\",\"CAGR (%)\",\"Sharpe Ratio\",\"Max Drawdown (%)\",\n",
    "              \"Number of Trades\",\"Win Rate (%)\",\"Avg PnL\",\"Median Holding (days)\",\"Stop Loss Hits\",\"Data Points\"]\n",
    "comparison_df = comparison_df[[c for c in cols_order if c in comparison_df.columns]]\n",
    "\n",
    "# Save to Excel\n",
    "comparison_df.to_excel(\"Trade_Comparison_Summary.xlsx\", index=False)\n",
    "print(\"✅ Saved comparison to Trade_Comparison_Summary.xlsx\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xmt0XJU9WqlJ"
   },
   "outputs": [],
   "source": [
    "# Calculate Trade Profit and Percentage Return for Original and Enhanced Trades\n",
    "#\n",
    "# Computes the profit and percentage return per trade based on the number of shares and price difference\n",
    "# between consecutive trade prices (assumed to be buy and sell prices via shift).\n",
    "\n",
    "original_trades_df['PnL'] = original_trades_df['Shares'] * (original_trades_df['Price'].shift(-1) - original_trades_df['Price'])\n",
    "original_trades_df['Return_%'] = (original_trades_df['PnL'] / (original_trades_df['Shares'] * original_trades_df['Price'])) * 100\n",
    "\n",
    "enhanced_trades_df['PnL'] = enhanced_trades_df['Shares'] * (enhanced_trades_df['Price'].shift(-1) - enhanced_trades_df['Price'])\n",
    "enhanced_trades_df['Return_%'] = (enhanced_trades_df['PnL'] / (enhanced_trades_df['Shares'] * enhanced_trades_df['Price'])) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpHUB-XcZQ72"
   },
   "outputs": [],
   "source": [
    "# Combine Buy and Sell Rows into Trade Summary DataFrame\n",
    "#\n",
    "# This function takes a DataFrame with alternating buy and sell rows,\n",
    "# pairs them to create trade records, and calculates PnL, percentage return,\n",
    "# and holding period for each trade.\n",
    "#\n",
    "# Usage:\n",
    "#   original_trades_df = combine_trades(original_trades_df)\n",
    "#   enhanced_trades_df = combine_trades(enhanced_trades_df)\n",
    "\n",
    "def combine_trades(df):\n",
    "    trades = []\n",
    "    for i in range(0, len(df), 2):  # Every BUY–SELL pair\n",
    "        buy_row = df.iloc[i]\n",
    "        sell_row = df.iloc[i+1] if i+1 < len(df) else None\n",
    "        if sell_row is not None:\n",
    "            buy_date = buy_row['Date']\n",
    "            buy_price = buy_row['Price']\n",
    "            sell_date = sell_row['Date']\n",
    "            sell_price = sell_row['Price']\n",
    "            pnl = (sell_price - buy_price) * buy_row['Shares']\n",
    "            ret_pct = (pnl / (buy_price * buy_row['Shares'])) * 100\n",
    "            holding_days = (pd.to_datetime(sell_date) - pd.to_datetime(buy_date)).days\n",
    "            trades.append([buy_date, buy_price, sell_date, sell_price, pnl, ret_pct, holding_days])\n",
    "    return pd.DataFrame(trades, columns=['Buy_Date', 'Buy_Price', 'Sell_Date', 'Sell_Price', 'PnL', 'Return_%', 'Holding_Days'])\n",
    "\n",
    "original_trades_df = combine_trades(original_trades_df)\n",
    "enhanced_trades_df = combine_trades(enhanced_trades_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 878
    },
    "id": "ag66QC_8VuCN",
    "outputId": "85226326-37a9-471a-db3e-30af19d0edac"
   },
   "outputs": [],
   "source": [
    "# Robust Evaluation of Original, Enhanced, and ML+StopLoss Trading Strategies\n",
    "# Debug + robust comparison builder\n",
    "import pandas as pd, numpy as np, os\n",
    "from datetime import timedelta\n",
    "\n",
    "# --- reuse your helper functions (copy them if not in scope) ---\n",
    "# If these functions exist already in your notebook, Python will use them.\n",
    "# Otherwise paste the definitions of ensure_series, compute_portfolio_metrics,\n",
    "# reconstruct_trades_from_log and trade_statistics from your previous cell here.\n",
    "\n",
    "# Quick checks\n",
    "print(\"USE_IN_MEMORY:\", USE_IN_MEMORY)\n",
    "print(\"'df' in globals():\", 'df' in globals())\n",
    "\n",
    "if 'df' in globals():\n",
    "    try:\n",
    "        print(\"df columns:\", df.columns.tolist())\n",
    "        display(df.head(3))\n",
    "    except Exception as e:\n",
    "        print(\"Error printing df:\", e)\n",
    "\n",
    "# Show whether files exist\n",
    "for f in [ORIG_TRADES_FILE, ENH_TRADES_FILE, ML_TRADES_FILE]:\n",
    "    print(f\"Exists '{f}':\", os.path.exists(f) if f else False)\n",
    "\n",
    "# Build portfolio_map more defensively\n",
    "portfolio_map = {}\n",
    "if USE_IN_MEMORY and 'df' in globals():\n",
    "    # Try common explicit names first\n",
    "    if 'Original_Portfolio' in df.columns:\n",
    "        portfolio_map['Original'] = df['Original_Portfolio']\n",
    "    if 'Enhanced_Portfolio' in df.columns:\n",
    "        portfolio_map['Enhanced'] = df['Enhanced_Portfolio']\n",
    "    if 'ML_Portfolio' in df.columns:\n",
    "        portfolio_map['ML (StopLoss)'] = df['ML_Portfolio']\n",
    "    # Try other heuristic column names (case-insensitive contains)\n",
    "    for c in df.columns:\n",
    "        if 'portfolio' in c.lower() and c not in portfolio_map.values():\n",
    "            # choose a readable key\n",
    "            key = c\n",
    "            if 'orig' in c.lower():\n",
    "                key = 'Original'\n",
    "            elif 'enh' in c.lower():\n",
    "                key = 'Enhanced'\n",
    "            elif 'ml' in c.lower() or 'optionc' in c.lower():\n",
    "                key = 'ML (StopLoss)'\n",
    "            portfolio_map.setdefault(key, df[c])\n",
    "\n",
    "# If no in-memory series, try to load CSV/Excel portfolio files as fallback\n",
    "if not portfolio_map:\n",
    "    # look for simple CSV files you might have produced\n",
    "    if os.path.exists(\"Original_Portfolio.csv\"):\n",
    "        p = pd.read_csv(\"Original_Portfolio.csv\", parse_dates=['Date'], index_col='Date')\n",
    "        portfolio_map['Original'] = p.iloc[:,0]\n",
    "    if os.path.exists(\"Enhanced_Portfolio.csv\"):\n",
    "        p = pd.read_csv(\"Enhanced_Portfolio.csv\", parse_dates=['Date'], index_col='Date')\n",
    "        portfolio_map['Enhanced'] = p.iloc[:,0]\n",
    "    if os.path.exists(\"ML_Portfolio.csv\"):\n",
    "        p = pd.read_csv(\"ML_Portfolio.csv\", parse_dates=['Date'], index_col='Date')\n",
    "        portfolio_map['ML (StopLoss)'] = p.iloc[:,0]\n",
    "\n",
    "print(\"Portfolio map keys found:\", list(portfolio_map.keys()))\n",
    "\n",
    "# Load trade logs if not present in memory\n",
    "original_trades_df = globals().get('original_trades_df', None)\n",
    "enhanced_trades_df = globals().get('enhanced_trades_df', None)\n",
    "ml_trades_df = globals().get('ml_trades_df', None)\n",
    "\n",
    "if original_trades_df is None and ORIG_TRADES_FILE and os.path.exists(ORIG_TRADES_FILE):\n",
    "    try:\n",
    "        original_trades_df = pd.read_csv(ORIG_TRADES_FILE)\n",
    "        print(\"Loaded original trades:\", original_trades_df.shape)\n",
    "    except Exception as e:\n",
    "        print(\"Could not load ORIG_TRADES_FILE:\", e)\n",
    "\n",
    "if enhanced_trades_df is None and ENH_TRADES_FILE and os.path.exists(ENH_TRADES_FILE):\n",
    "    try:\n",
    "        enhanced_trades_df = pd.read_csv(ENH_TRADES_FILE)\n",
    "        print(\"Loaded enhanced trades:\", enhanced_trades_df.shape)\n",
    "    except Exception as e:\n",
    "        print(\"Could not load ENH_TRADES_FILE:\", e)\n",
    "\n",
    "if ml_trades_df is None and ML_TRADES_FILE and os.path.exists(ML_TRADES_FILE):\n",
    "    try:\n",
    "        if ML_TRADES_FILE.lower().endswith('.csv'):\n",
    "            ml_trades_df = pd.read_csv(ML_TRADES_FILE)\n",
    "        else:\n",
    "            ml_trades_df = pd.read_excel(ML_TRADES_FILE)\n",
    "        print(\"Loaded ML trades:\", ml_trades_df.shape)\n",
    "    except Exception as e:\n",
    "        print(\"Could not load ML_TRADES_FILE:\", e)\n",
    "\n",
    "# Quick look at trade columns (helpful for diagnosing empty outputs)\n",
    "for name, df_tr in [('original_trades_df', original_trades_df),\n",
    "                    ('enhanced_trades_df', enhanced_trades_df),\n",
    "                    ('ml_trades_df', ml_trades_df)]:\n",
    "    if df_tr is None:\n",
    "        print(f\"{name} is None\")\n",
    "    else:\n",
    "        print(f\"{name} columns:\", df_tr.columns.tolist())\n",
    "        display(df_tr.head(2))\n",
    "\n",
    "# Now compute metrics safely\n",
    "results = []\n",
    "trade_summaries = {}\n",
    "\n",
    "# helper to safe-run compute_portfolio_metrics\n",
    "def safe_compute(name, series):\n",
    "    try:\n",
    "        return compute_portfolio_metrics(series)\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing portfolio metrics for {name}: {e}\")\n",
    "        # return NaN-filled dictionary with expected keys\n",
    "        return {\"Final Value\": np.nan, \"Total Return (%)\": np.nan, \"CAGR (%)\": np.nan,\n",
    "                \"Sharpe Ratio\": np.nan, \"Max Drawdown (%)\": np.nan, \"Data Points\": 0}\n",
    "\n",
    "for name, series in portfolio_map.items():\n",
    "    metrics = safe_compute(name, series)\n",
    "    # attach trade stats if available\n",
    "    if name.startswith('Original') and original_trades_df is not None:\n",
    "        trades_parsed = reconstruct_trades_from_log(original_trades_df)\n",
    "        ts = trade_statistics(trades_parsed)\n",
    "        trade_summaries[name] = trades_parsed\n",
    "    elif name.startswith('Enhanced') and enhanced_trades_df is not None:\n",
    "        trades_parsed = reconstruct_trades_from_log(enhanced_trades_df)\n",
    "        ts = trade_statistics(trades_parsed)\n",
    "        trade_summaries[name] = trades_parsed\n",
    "    elif 'ML' in name and ml_trades_df is not None:\n",
    "        trades_parsed = reconstruct_trades_from_log(ml_trades_df)\n",
    "        ts = trade_statistics(trades_parsed)\n",
    "        trade_summaries[name] = trades_parsed\n",
    "    else:\n",
    "        ts = trade_statistics(pd.DataFrame())\n",
    "    combined = {\"Strategy\": name}\n",
    "    combined.update(metrics)\n",
    "    combined.update(ts)\n",
    "    results.append(combined)\n",
    "\n",
    "# If no portfolio series were found, fall back to using trade logs only (keeps DataFrame non-empty)\n",
    "if len(results) == 0:\n",
    "    print(\"No portfolio series found — building comparison from trade logs only.\")\n",
    "    fallback = [('Original', original_trades_df), ('Enhanced', enhanced_trades_df), ('ML (StopLoss)', ml_trades_df)]\n",
    "    for name, tdf in fallback:\n",
    "        if tdf is None:\n",
    "            continue\n",
    "        trades_parsed = reconstruct_trades_from_log(tdf)\n",
    "        ts = trade_statistics(trades_parsed)\n",
    "        row = {\"Strategy\": name, \"Final Value\": np.nan, \"Total Return (%)\": np.nan,\n",
    "               \"CAGR (%)\": np.nan, \"Sharpe Ratio\": np.nan, \"Max Drawdown (%)\": np.nan,\n",
    "               \"Data Points\": 0}\n",
    "        row.update(ts)\n",
    "        results.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "\n",
    "# reorder columns if present\n",
    "cols_order = [\"Strategy\",\"Final Value\",\"Total Return (%)\",\"CAGR (%)\",\"Sharpe Ratio\",\"Max Drawdown (%)\",\n",
    "              \"Number of Trades\",\"Win Rate (%)\",\"Avg PnL\",\"Median Holding (days)\",\"Stop Loss Hits\",\"Data Points\"]\n",
    "comparison_df = comparison_df[[c for c in cols_order if c in comparison_df.columns]]\n",
    "\n",
    "# Save & show\n",
    "comparison_df.to_excel(\"Trade_Comparison_Summary.xlsx\", index=False)\n",
    "print(\"✅ Saved comparison to Trade_Comparison_Summary.xlsx\")\n",
    "print(comparison_df)\n",
    "# Also save each trade summary for inspection\n",
    "for k,v in trade_summaries.items():\n",
    "    fname = f\"trades_summary_{k.replace(' ','_')}.csv\"\n",
    "    v.to_csv(fname, index=False)\n",
    "    print(\"Saved\", fname, \"rows:\", len(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElWXrBkKZllK",
    "outputId": "74d1f0d9-4f32-42cf-dae0-4baa33b8a9a4"
   },
   "outputs": [],
   "source": [
    "# === Strategy Performance Metrics Summary ===\n",
    "# Computes trade-level metrics: Final portfolio value, total return %, CAGR, Sharpe ratio (per trade), and win rate %\n",
    "# for Original, Enhanced, and ML strategies from their respective trade logs.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_strategy_metrics(trades_df, initial_capital=100000):\n",
    "    \"\"\"Compute Final Value, Total Return %, CAGR, Sharpe Ratio, and Win Rate from trade logs.\"\"\"\n",
    "\n",
    "    # Sort by Buy_Date just to be safe\n",
    "    trades_df = trades_df.sort_values('Buy_Date').reset_index(drop=True)\n",
    "\n",
    "    # Portfolio growth simulation\n",
    "    capital = initial_capital\n",
    "    equity_curve = []\n",
    "\n",
    "    for _, row in trades_df.iterrows():\n",
    "        trade_return = row['Return_%'] / 100\n",
    "        capital *= (1 + trade_return)\n",
    "        equity_curve.append(capital)\n",
    "\n",
    "    # Final value & total return\n",
    "    final_value = equity_curve[-1] if equity_curve else initial_capital\n",
    "    total_return_pct = ((final_value / initial_capital) - 1) * 100\n",
    "\n",
    "    # CAGR\n",
    "    if len(trades_df) > 0:\n",
    "        start_date = pd.to_datetime(trades_df['Buy_Date'].iloc[0])\n",
    "        end_date = pd.to_datetime(trades_df['Sell_Date'].iloc[-1])\n",
    "        years = (end_date - start_date).days / 365.25\n",
    "        cagr = ((final_value / initial_capital) ** (1 / years) - 1) * 100 if years > 0 else np.nan\n",
    "    else:\n",
    "        cagr = np.nan\n",
    "\n",
    "    # Sharpe ratio (per trade basis, risk-free rate = 0)\n",
    "    sharpe_ratio = np.nan\n",
    "    if trades_df['Return_%'].std() != 0 and len(trades_df) > 1:\n",
    "        sharpe_ratio = (trades_df['Return_%'].mean() / trades_df['Return_%'].std()) * np.sqrt(len(trades_df))\n",
    "\n",
    "    # Win rate\n",
    "    win_rate = (trades_df['PnL'] > 0).mean() * 100 if len(trades_df) > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"Trades\": len(trades_df),\n",
    "        \"Final Value\": round(final_value, 2),\n",
    "        \"Total Return (%)\": round(total_return_pct, 2),\n",
    "        \"CAGR (%)\": round(cagr, 2) if not np.isnan(cagr) else np.nan,\n",
    "        \"Sharpe Ratio\": round(sharpe_ratio, 2) if not np.isnan(sharpe_ratio) else np.nan,\n",
    "        \"Win Rate (%)\": round(win_rate, 2)\n",
    "    }\n",
    "\n",
    "# --- RUN FOR ALL THREE STRATEGIES ---\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Original Strategy\": compute_strategy_metrics(original_trades_df),\n",
    "    \"Enhanced Strategy\": compute_strategy_metrics(enhanced_trades_df),\n",
    "    \"ML Strategy\": compute_strategy_metrics(ml_trades_df)\n",
    "}).T  # Transpose so strategies are rows\n",
    "\n",
    "# Save to Excel\n",
    "comparison_df.to_excel(\"Trade_Comparison_Summary.xlsx\")\n",
    "\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2WPdP5xLzJg",
    "outputId": "b1180ad7-d758-4d91-c7ce-324ef9bab3c8"
   },
   "outputs": [],
   "source": [
    "# 1. Check if column exists\n",
    "print(\"Has Stop_Loss_Hit column:\", \"Stop_Loss_Hit\" in trades.columns)\n",
    "\n",
    "# 2. If it exists, count how many trades hit stop loss\n",
    "if \"Stop_Loss_Hit\" in trades.columns:\n",
    "    print(\"Number of stop loss hits:\", trades[\"Stop_Loss_Hit\"].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "th4g9AZQO4IJ",
    "outputId": "d4e89846-8232-4199-9a05-f11325926599"
   },
   "outputs": [],
   "source": [
    "print(\"Original trades columns:\", original_trades_summary.columns.tolist())\n",
    "print(\"Enhanced trades columns:\", enhanced_trades_summary.columns.tolist())\n",
    "print(\"ML trades columns:\", ml_trades.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8goc-CvyPMyV",
    "outputId": "3287754e-5c62-4e0d-d4c9-71682334cc7f"
   },
   "outputs": [],
   "source": [
    "# Convert ML Trade Action Log into Trade Summary with PnL, Returns, and Holding Period\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load ML trade log\n",
    "ml_log = pd.read_csv(\"ml_trade_log.csv\")\n",
    "\n",
    "# Ensure Date column is datetime\n",
    "ml_log['Date'] = pd.to_datetime(ml_log['Date'])\n",
    "\n",
    "# Sort by date (just in case)\n",
    "ml_log = ml_log.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Prepare list for trade summaries\n",
    "trades = []\n",
    "buy_date, buy_price = None, None\n",
    "\n",
    "# Loop through trades\n",
    "for _, row in ml_log.iterrows():\n",
    "    if row['Action'].lower() == 'buy':\n",
    "        buy_date = row['Date']\n",
    "        buy_price = row['Price']\n",
    "    elif row['Action'].lower() == 'sell' and buy_date is not None:\n",
    "        sell_date = row['Date']\n",
    "        sell_price = row['Price']\n",
    "\n",
    "        # Calculate PnL and return %\n",
    "        pnl = sell_price - buy_price\n",
    "        ret_pct = (sell_price - buy_price) / buy_price * 100\n",
    "        holding_days = (sell_date - buy_date).days\n",
    "\n",
    "        trades.append({\n",
    "            'Buy_Date': buy_date,\n",
    "            'Buy_Price': buy_price,\n",
    "            'Sell_Date': sell_date,\n",
    "            'Sell_Price': sell_price,\n",
    "            'PnL': pnl,\n",
    "            'Return_%': ret_pct,\n",
    "            'Holding_Days': holding_days\n",
    "        })\n",
    "\n",
    "        # Reset buy info\n",
    "        buy_date, buy_price = None, None\n",
    "\n",
    "# Convert to DataFrame\n",
    "ml_trade_summary = pd.DataFrame(trades)\n",
    "\n",
    "print(\"ML Trade Summary:\")\n",
    "print(ml_trade_summary.head())\n",
    "\n",
    "# Save for later merge\n",
    "ml_trade_summary.to_csv(\"ml_trade_summary.csv\", index=False)\n",
    "print(\"\\nSaved ML trade summary to ml_trade_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2q2G22uA4dam",
    "outputId": "75281d9e-9f7c-42d2-9591-bf4db7789b29"
   },
   "outputs": [],
   "source": [
    "# Backtesting ML-Predicted Sentiment Strategy with Stop-Loss and Overfitting Fix Options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CSV_FILE = \"ml_predictions.csv\"  # change to your dataset path\n",
    "initial_cash = 100000\n",
    "stop_loss_pct = 0.02  # 2% stop loss\n",
    "# -----------------------------------------\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Ensure needed columns exist\n",
    "required_cols = ['Date', 'Close', 'ML_Predicted']\n",
    "for col in required_cols:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Missing column: {col}\")\n",
    "\n",
    "# Function to run backtest\n",
    "def backtest(data, use_stoploss=False, fix_overfitting=False):\n",
    "    cash = initial_cash\n",
    "    position = 0\n",
    "    entry_price = 0\n",
    "    portfolio_values = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        sentiment = data['ML_Predicted'].iloc[i]\n",
    "        price = data['Close'].iloc[i]\n",
    "\n",
    "        # --- Overfitting Fix: skip if previous sentiment was same ---\n",
    "        if fix_overfitting and i > 0:\n",
    "            if sentiment == data['ML_Predicted'].iloc[i-1]:\n",
    "                portfolio_values.append(cash + position * price)\n",
    "                continue\n",
    "\n",
    "        # --- Stop Loss Condition ---\n",
    "        if use_stoploss and position > 0:\n",
    "            if price <= entry_price * (1 - stop_loss_pct):\n",
    "                cash += position * price\n",
    "                position = 0\n",
    "                entry_price = 0\n",
    "\n",
    "        # --- Execute Trades ---\n",
    "        if sentiment == \"Bullish\" and position == 0:\n",
    "            position = cash // price\n",
    "            cash -= position * price\n",
    "            entry_price = price\n",
    "        elif sentiment == \"Bearish\" and position > 0:\n",
    "            cash += position * price\n",
    "            position = 0\n",
    "            entry_price = 0\n",
    "\n",
    "        portfolio_values.append(cash + position * price)\n",
    "\n",
    "    final_value = portfolio_values[-1]\n",
    "    total_return_pct = ((final_value - initial_cash) / initial_cash) * 100\n",
    "    return final_value, total_return_pct\n",
    "\n",
    "# Run scenarios\n",
    "only_overfit_val, only_overfit_ret = backtest(df, use_stoploss=False, fix_overfitting=True)\n",
    "only_stoploss_val, only_stoploss_ret = backtest(df, use_stoploss=True, fix_overfitting=False)\n",
    "both_val, both_ret = backtest(df, use_stoploss=True, fix_overfitting=True)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n===== RESULTS =====\")\n",
    "print(f\"Only Overfitting Fix: Final Value = {only_overfit_val:.2f}, Return = {only_overfit_ret:.2f}%\")\n",
    "print(f\"Only Stop-Loss Fix : Final Value = {only_stoploss_val:.2f}, Return = {only_stoploss_ret:.2f}%\")\n",
    "print(f\"Both Fixes Combined: Final Value = {both_val:.2f}, Return = {both_ret:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-C5umf84g1Cx",
    "outputId": "985303a7-2258-4010-a21d-b4ab02b9e475"
   },
   "outputs": [],
   "source": [
    "# Backtesting and Comparing Original, Enhanced, and ML-Based Sentiment Strategies with Overfitting and Stop-Loss Adjustments\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load your ML predictions file\n",
    "# -------------------------------\n",
    "df = pd.read_csv(\"ml_predictions.csv\")  # Replace with your actual file\n",
    "\n",
    "# Ensure we have these columns\n",
    "# 'Date', 'Close', 'ML_Predicted_Sentiment', 'Enhanced_Sentiment', 'Original_Sentiment'\n",
    "# ML_Predicted_Sentiment should be one of ['Bullish','Bearish','Neutral']\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Backtest function\n",
    "# -------------------------------\n",
    "def backtest_strategy(df, sentiment_col, stop_loss=None):\n",
    "    initial_capital = 100000\n",
    "    position = 0  # 1 means holding stock, 0 means cash\n",
    "    cash = initial_capital\n",
    "    entry_price = 0\n",
    "    trades = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        sentiment = df[sentiment_col].iloc[i]\n",
    "        price = df['Close'].iloc[i]\n",
    "\n",
    "        # Stop-loss check\n",
    "        if position == 1 and stop_loss is not None:\n",
    "            if (price - entry_price) / entry_price <= -stop_loss:\n",
    "                # Sell due to stop-loss\n",
    "                cash = position * price\n",
    "                trades.append((df['Date'].iloc[i], 'SELL_SL', price))\n",
    "                position = 0\n",
    "                continue\n",
    "\n",
    "        if sentiment == 'Bullish' and position == 0:\n",
    "            position = cash / price\n",
    "            entry_price = price\n",
    "            cash = 0\n",
    "            trades.append((df['Date'].iloc[i], 'BUY', price))\n",
    "\n",
    "        elif sentiment == 'Bearish' and position > 0:\n",
    "            cash = position * price\n",
    "            trades.append((df['Date'].iloc[i], 'SELL', price))\n",
    "            position = 0\n",
    "\n",
    "    final_value = cash if position == 0 else position * df['Close'].iloc[-1]\n",
    "    total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "    return final_value, total_return\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Overfitting fix function\n",
    "# -------------------------------\n",
    "def apply_overfitting_fix(pred_series):\n",
    "    fixed = pred_series.copy()\n",
    "    for i in range(1, len(fixed)):\n",
    "        if fixed.iloc[i] == fixed.iloc[i-1]:\n",
    "            continue\n",
    "        else:\n",
    "            # Example: smooth single-day noise\n",
    "            if i < len(fixed)-1 and fixed.iloc[i-1] == fixed.iloc[i+1]:\n",
    "                fixed.iloc[i] = fixed.iloc[i-1]\n",
    "    return fixed\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Create strategy variants\n",
    "# -------------------------------\n",
    "\n",
    "# Original ML\n",
    "df['ML_Original'] = df['ML_Predicted']\n",
    "\n",
    "# Only Overfitting\n",
    "df['ML_Only_Overfit'] = apply_overfitting_fix(df['ML_Predicted'])\n",
    "\n",
    "# Only Stop-Loss (no overfit fix)\n",
    "df['ML_Only_StopLoss'] = df['ML_Predicted']\n",
    "\n",
    "# Overfit + Stop-Loss\n",
    "df['ML_Overfit_StopLoss'] = apply_overfitting_fix(df['ML_Predicted'])\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Compare all strategies\n",
    "# -------------------------------\n",
    "results = {\n",
    "    \"Original Strategy\": backtest_strategy(df, 'Sentiment'),\n",
    "    \"Enhanced Strategy\": backtest_strategy(df, 'Sentiment_Enhanced'),\n",
    "    \"ML Original\": backtest_strategy(df, 'ML_Original'),\n",
    "    \"ML Only Overfit\": backtest_strategy(df, 'ML_Only_Overfit'),\n",
    "    \"ML Only StopLoss\": backtest_strategy(df, 'ML_Only_StopLoss', stop_loss=0.02),  # 2% stop loss\n",
    "    \"ML Overfit + StopLoss\": backtest_strategy(df, 'ML_Overfit_StopLoss', stop_loss=0.02)\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Show results in DataFrame\n",
    "# -------------------------------\n",
    "results_df = pd.DataFrame(results, index=['Final Value', 'Total Return (%)']).T\n",
    "print(\"\\n📊 Strategy Performance Comparison:\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
